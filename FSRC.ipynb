{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V3VS85L1i6C"
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "wy9U9E3kvRTK",
    "outputId": "f2fa9b49-a620-43cd-a3f8-5617bc2574f1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mG5xTy95vRV1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir(\"/content/drive/My Drive/MS Thesis/Minimum Spanning Tree FAST\")\n",
    "os.chdir(\"/content/drive/My Drive/MS Thesis/FAST done In Home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "8oFBE1ndvYDh",
    "outputId": "967f8e94-57df-4369-e934-e8263bb62528"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive/MS Thesis/FAST done In Home\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYDPPPvJwJsc"
   },
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "25ts2dUk1teJ",
    "outputId": "5a31c906-1660-4e59-fec2-0db09cd7160f"
   },
   "outputs": [],
   "source": [
    "pip install pyitlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "FFk3wzQlwMti",
    "outputId": "a94d396f-b6b8-4a08-ebc4-6f9c98103c90"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import RandomForestClassifier as RF, AdaBoostClassifier as AB\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# from scipy.stats import skew, kurtosis, iqr, median_absolute_deviation, entropy\n",
    "from scipy.stats import skew, kurtosis, iqr,  entropy\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "from pyitlib import discrete_random_variable as drv\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import os\n",
    "import time\n",
    "from scipy.stats import chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "import random\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "from multiprocess import Pool, Manager\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyL1i55O2exr"
   },
   "source": [
    "# discritize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name =\"FAST_v6_2_binary_method_base\"\n",
    "irrelevant_feature_storing_file_name = \"FAST_v6_2_binary_method_base irrelevant feature\"\n",
    "per_fold_feature_storing_file_name = \"FAST_v6_2_binary_method_base per fold feature\"\n",
    "myfile = open(output_file_name +\".txt\",\"w+\")\n",
    "irrelevant_feature_storing_file = open(irrelevant_feature_storing_file_name +\".txt\",\"w+\")\n",
    "per_fold_feature_storing_file = open(per_fold_feature_storing_file_name +\".txt\",\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization_level = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_feture_for_cluster_evaluation = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feature_list_for_dataset_contains_one_value(dataset, df):\n",
    "#   print(\"Dataset: -------->>>>>>>>>> \", dataset)\n",
    "#   # t_df=undiscretized_df\n",
    "#   t_df = df\n",
    "#   t_df.shape\n",
    "#   class_df = t_df['0']\n",
    "# #   print(class_df.shape)\n",
    "# #   print (class_df.head(5))\n",
    "#   feature_df = t_df.drop(columns=['0'])\n",
    "#   feature_columns =list(feature_df.columns)\n",
    "# #   print(feature_columns)\n",
    "\n",
    "#   feature_values = []\n",
    "# #   print(\"--------------------------------------------------------\")\n",
    "#   for colum_name in feature_columns:\n",
    "#     unique_val = np.unique(feature_df[colum_name].values).size\n",
    "#     if unique_val < 6:\n",
    "#       print(\"gene name \",colum_name,\" unique_val \", unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekZkpmg91Kjf"
   },
   "outputs": [],
   "source": [
    "def get_discritized_df(df):\n",
    "  # t_df=undiscretized_df\n",
    "  t_df = df.copy()\n",
    "#   t_df.shape\n",
    "  class_df = t_df['0']\n",
    "  # print(class_df.shape)\n",
    "  # print (class_df.head(5))\n",
    "  feature_df = t_df.drop(columns=['0'])\n",
    "  feature_columns =list(feature_df.columns)\n",
    "#   print(feature_columns)\n",
    "#   columns.remove('0')\n",
    "#   print(columns)\n",
    "\n",
    "  # print(feature_df.shape)\n",
    "  # print (feature_df.head(3))\n",
    "  # print(undiscretized_df.shape, t_df.shape, feature_df.shape)\n",
    "  feature_values = feature_df.values.astype(float)\n",
    "  # print (feature_values.shape)\n",
    "  enc = KBinsDiscretizer(n_bins=discretization_level, encode='ordinal', strategy='uniform')\n",
    "  enc.fit(feature_values)\n",
    "  # feature_values = enc.transform(feature_values)\n",
    "  feature_values = enc.transform(feature_values).astype(np.int32)\n",
    "  # print (feature_values.shape)\n",
    "  # print (feature_values[0])\n",
    "  # numpy array of size 31x36\n",
    "  # pd.DataFrame(data=matrix,\n",
    "  #           index=np.array(range(1, 32)),\n",
    "  #           columns=np.array(range(1, 37)))\n",
    "  # new_feature_df = pd.DataFrame(data=feature_values, columns = [str(i) for i in range(1, len(undiscretized_df.columns))] )\n",
    "#   new_feature_df = pd.DataFrame(data=feature_values, columns = [str(i) for i in range(1, len(df.columns))] )\n",
    "  new_feature_df = pd.DataFrame(data=feature_values, columns = feature_columns )\n",
    "  # print(type(undiscretized_df))\n",
    "  # print(undiscretized_df.head(3))\n",
    "  # print(type(new_feature_df))\n",
    "  # print(new_feature_df.head(3))\n",
    "  discretized_df = pd.concat([class_df, new_feature_df], axis=1)\n",
    "#   print('in discretized_df')\n",
    "#   print('Original df shape ',df.shape)\n",
    "#   print(df.head(2))\n",
    "#   print('After discritizing df shape ',discretized_df.shape)\n",
    "#   print(discretized_df.head(2))\n",
    "  return discretized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_discritized_df_for_plos_one(df):\n",
    "#   # t_df=undiscretized_df\n",
    "#   t_df = df.copy()\n",
    "# #   t_df.shape\n",
    "#   class_df = t_df['0']\n",
    "# #   print(class_df.shape)\n",
    "# #   print (class_df.head(5))\n",
    "#   feature_df = t_df.drop(columns=['0'])\n",
    "#   feature_columns =list(feature_df.columns)\n",
    "# #   print(feature_columns)\n",
    "  \n",
    "#   feature_values = []\n",
    "# #   print(\"--------------------------------------------------------\")\n",
    "#   for colum_name in feature_columns:\n",
    "#     one_column_df = feature_df[colum_name]\n",
    "#     mean_val = one_column_df.mean(axis = 0)\n",
    "#     std_val = one_column_df.std(axis = 0)\n",
    "# #     print(\"original one_column_df\\n\", one_column_df, ' mean ', mean_val, ' std ', std_val)\n",
    "# #     print(\"mean_val - std_val \", mean_val - std_val)\n",
    "# #     print(\"mean_val + std_val \", mean_val + std_val)\n",
    "    \n",
    "#     conditions = [one_column_df.values < (mean_val - std_val),  one_column_df.values > (mean_val + std_val)]\n",
    "#     choices = [-1, 1]\n",
    "\n",
    "#     one_column_df = np.select(conditions, choices, default=0)\n",
    "# #     now one_column_df is a list beacause of np.select function\n",
    "#     feature_values.append(one_column_df)\n",
    "    \n",
    "# #     print(\"after change one_column_df type \", type(one_column_df), \"\\n\", one_column_df)\n",
    "# #   print(\"-----------------------------------------\")\n",
    "#   feature_values= np.array(feature_values)\n",
    "#   feature_values = feature_values.transpose()\n",
    "# #   print(type(feature_values), feature_values.shape)\n",
    "# #   print(feature_values)\n",
    "#   new_feature_df = pd.DataFrame(data = feature_values, columns = feature_columns )\n",
    "#   # print(type(undiscretized_df))\n",
    "#   # print(undiscretized_df.head(3))\n",
    "#   # print(type(new_feature_df))\n",
    "#   # print(new_feature_df.head(3))\n",
    "#   discretized_df = pd.concat([class_df, new_feature_df], axis=1)\n",
    "# #   print('in discretized_df')\n",
    "# #   print('Original df shape ',df.shape)\n",
    "# #   print(df.head(2))\n",
    "# #   print('After discritizing df shape ',discretized_df.shape)\n",
    "# #   print(discretized_df.head(2))\n",
    "#   return discretized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_for_dataset_except_single_value_column(df):\n",
    "  t_df = df\n",
    "  class_df = t_df['0']\n",
    "\n",
    "  feature_df = t_df.drop(columns=['0'])\n",
    "  feature_columns =list(feature_df.columns)\n",
    "  \n",
    "  only_one_val_feature_list = []\n",
    "  new_feature_columns = feature_columns.copy()\n",
    "\n",
    "  for colum_name in feature_columns:\n",
    "    unique_val = np.unique(feature_df[colum_name].values).size\n",
    "    if unique_val == 1:\n",
    "      # only_one_val_feature_list.append(colum_name)\n",
    "      new_feature_columns.remove(colum_name)\n",
    "\n",
    "  new_feature_df = feature_df[ new_feature_columns ]\n",
    "  new_df = pd.concat([class_df, new_feature_df], axis=1)\n",
    "\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply the min-max scaling in Pandas using the .min() and .max() methods\n",
    "# def get_min_max_normalized_df(df):\n",
    "#   # copy the dataframe\n",
    "#   df_norm = df.copy()\n",
    "#   # apply min-max scaling\n",
    "#   for column in df_norm.columns:\n",
    "#       df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
    "      \n",
    "#   return df_norm\n",
    "    \n",
    "# # call the min_max_scaling function\n",
    "# # df_cars_normalized = min_max_scaling(df_cars)\n",
    "\n",
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # # create a scaler object\n",
    "# # scaler = MinMaxScaler()\n",
    "# # # fit and transform the data\n",
    "# # df_norm = pd.DataFrame(scaler.fit_transform(df_cars), columns=df_cars.columns)\n",
    "\n",
    "# # df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_categorical_feature(dataset, df):\n",
    "#   print(\"Dataset: -------->>>>>>>>>> \", dataset)\n",
    "#   # t_df=undiscretized_df\n",
    "#   t_df = df\n",
    "#   t_df.shape\n",
    "#   class_df = t_df['0']\n",
    "# #   print(class_df.shape)\n",
    "# #   print (class_df.head(5))\n",
    "#   feature_df = t_df.drop(columns=['0'])\n",
    "#   feature_columns =list(feature_df.columns)\n",
    "# #   print(feature_columns)\n",
    "  \n",
    "#   feature_values = []\n",
    "# #   print(\"--------------------------------------------------------\")\n",
    "#   for colum_name in feature_columns:\n",
    "#     unique_val = np.unique(feature_df[colum_name].values).size\n",
    "#     if unique_val < 6:\n",
    "#       print(\"gene name \",colum_name,\" unique_val \", unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ten_fold_feature_list(dir, filename):\n",
    "  file1 = open(dir + filename + '_per_fold.txt', 'r')\n",
    "  Lines = file1.readlines()\n",
    "  file1.close()\n",
    "\n",
    "  all_fold_feature_list =[]\n",
    "#   count = 0\n",
    "  # Strips the newline character\n",
    "  \n",
    "  for line in Lines:\n",
    "#     count += 1\n",
    "#     print(count)\n",
    "#     print(line.strip())\n",
    "    s = line.strip()\n",
    "#     print(type(s))\n",
    "    res = ast.literal_eval(s)   \n",
    "#     print(res)\n",
    "#     print(type(res))\n",
    "#     print(res[0])\n",
    "    all_fold_feature_list.append(res)\n",
    "\n",
    "  return all_fold_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast \n",
    "# def get_feature_list_with_frequency_count(dir, filename):\n",
    "#   file1 = open(dir + filename + '_per_fold.txt', 'r')\n",
    "#   Lines = file1.readlines()\n",
    "#   file1.close()\n",
    "\n",
    "#   all_fold_feature_list =[]\n",
    "# #   count = 0\n",
    "#   # Strips the newline character\n",
    "  \n",
    "#   for line in Lines:\n",
    "# #     count += 1\n",
    "# #     print(count)\n",
    "# #     print(line.strip())\n",
    "#     s = line.strip()\n",
    "# #     print(type(s))\n",
    "#     res = ast.literal_eval(s)   \n",
    "# #     print(res)\n",
    "# #     print(type(res))\n",
    "# #     print(res[0])\n",
    "#     all_fold_feature_list.extend(res)\n",
    "# #     print(len(res))\n",
    "\n",
    "# #   print(len(all_fold_feature_list))\n",
    "# #   print(all_fold_feature_list)\n",
    "\n",
    "#   elements_count = {}\n",
    "#   for element in all_fold_feature_list:\n",
    "#    # checking whether it is in the dict or not\n",
    "#     if element in elements_count:\n",
    "#       # incerementing the count by 1\n",
    "#       elements_count[element] += 1\n",
    "#     else:\n",
    "#       # setting the count to 1\n",
    "#       elements_count[element] = 1\n",
    "  \n",
    "# #   # printing the elements frequencies\n",
    "# #   for key, value in elements_count.items():\n",
    "# #      print(f\"{key}: {value}\")\n",
    "\n",
    "#   sorted_elements_list = list (OrderedDict(sorted(elements_count.items(),reverse=True, key=itemgetter(1))) )\n",
    "\n",
    "#   return sorted_elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'0':[1, 0, 0, 0, 1, 0],\n",
    "#         'A1BG':[3.841, 4.414, 4.778, 4.019, 7.046, 6.419],\n",
    "#         'A2LD1':[6.299, 5.893, 5.219, 5.836, 7.142, 7.641],\n",
    "#         'A2M':[12.814, 13.103, 11.92, 10.871, 13.235, 12.169] }\n",
    "  \n",
    "# df = pd.DataFrame(data)\n",
    "# undiscretized_df = df\n",
    "# print(undiscretized_df)\n",
    "# discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# print(discretized_df)\n",
    "# print(discretized_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "un_0MNKS-1Iv"
   },
   "source": [
    "# Get selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, feature1, feature2):\n",
    "    x_N = np.unique(df[feature1].values.astype(np.int32)).size\n",
    "    y_N = np.unique(df[feature2].values.astype(np.int32)).size\n",
    "    N = df.shape[0]\n",
    "    mi_bias_corrected = drv.information_mutual(df[feature1].values.astype(np.int32), df[feature2].values.astype(np.int32)) - ( ((x_N-1)*(y_N-1)) / (2*N*0.69314718056) )\n",
    "    return mi_bias_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE ( (ln(2)/ln(N)) * rel) - ( (I-1)*(J-1) )/ 2*N*ln(N) is used for bias correction\n",
    "def calculate_relevance_or_redundance_value_bias_corrected_with_max_entropy_normalization_new(df, feature1, feature2):\n",
    "    x_N = np.unique(df[feature1].values.astype(np.int32)).size\n",
    "    y_N = np.unique(df[feature2].values.astype(np.int32)).size\n",
    "    N = df.shape[0]\n",
    "    mi_bias_corrected_with_max_entropy_normalization_new = ( (0.69314718056 / np.log(N)) * drv.information_mutual(df[feature1].values.astype(np.int32), df[feature2].values.astype(np.int32)) ) - ( ((x_N-1)*(y_N-1)) / (2*N* np.log(N)) )\n",
    "    return mi_bias_corrected_with_max_entropy_normalization_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_complementary_information_value_bias_corrected_without_normalization(df,feature1, feature2, class_label):\n",
    "    x_N = np.unique(df[feature1].values.astype(np.int32)).size\n",
    "    y_N = np.unique(df[feature2].values.astype(np.int32)).size\n",
    "    k_N = np.unique(df[class_label].values.astype(np.int32)).size\n",
    "    N = df.shape[0]\n",
    "    comp_mi_bias_corrected = drv.information_mutual_conditional(df[feature1].values.astype(np.int32), df[feature2].values.astype(np.int32), df[class_label].values.astype(np.int32)) - ( ((x_N-1) * (y_N-1) * k_N) / (2*N*0.69314718056) )\n",
    "    return comp_mi_bias_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_critical_value(df, feature1, feature2, N):\n",
    "    ddf = (np.unique(df[feature1].values.astype(np.int32)).size - 1) * (np.unique(df[feature2].values.astype(np.int32)).size - 1)\n",
    "    value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_critical_value_for_max_entropy_normalization_new(df, feature1, feature2, N):\n",
    "    ddf = (np.unique(df[feature1].values.astype(np.int32)).size - 1) * (np.unique(df[feature2].values.astype(np.int32)).size - 1)\n",
    "    value = chi2.ppf(confidence_interval, ddf)/ (2*N*np.log(N))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_complementary_critical_value(df, feature1, feature2, class_label, N):\n",
    "    ddf = (np.unique(df[feature1].values.astype(np.int32)).size - 1) * (np.unique(df[feature2].values.astype(np.int32)).size - 1) * np.unique(df[class_label].values.astype(np.int32)).size\n",
    "    value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_critical_value_using_Rrc_criteria(df, candidate_feature, selected_feature_list, class_label, N):\n",
    "#     N = df.shape[0]\n",
    "    ddf_relevance = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[class_label].values.astype(np.int32)).size - 1)\n",
    "    ddf_redundance_list = []\n",
    "    ddf_complementary_list = []\n",
    "    \n",
    "    for feature in selected_feature_list:\n",
    "        ddf_redundance = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[feature].values.astype(np.int32)).size - 1)\n",
    "        ddf_complementary = (np.unique(df[candidate_feature].values.astype(np.int32)).size - 1) * (np.unique(df[feature].values.astype(np.int32)).size - 1) * np.unique(df[class_label].values.astype(np.int32)).size\n",
    "        ddf_redundance_list.append( ddf_redundance )\n",
    "        ddf_complementary_list.append( ddf_complementary )\n",
    "    \n",
    "    ddf = ddf_relevance + np.mean(np.array(ddf_complementary_list)) - np.mean(np.array(ddf_redundance_list))\n",
    "    Rrc_critical_value = chi2.ppf(confidence_interval, ddf)/ (2*N*0.69314718056)\n",
    "    \n",
    "    redundance_ddf = np.mean(np.array(ddf_redundance_list))\n",
    "    redundance_critical_value = chi2.ppf(confidence_interval, redundance_ddf)/ (2*N*0.69314718056)\n",
    "    \n",
    "    relevance_critical_value = chi2.ppf(confidence_interval, ddf_relevance)/ (2*N*0.69314718056)\n",
    "    return relevance_critical_value, redundance_critical_value, Rrc_critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8t4YRIE8BXWA"
   },
   "outputs": [],
   "source": [
    "def select_threshold_value(df, columns, class_label):\n",
    "  # m= number of features in the dataset\n",
    "  m = len(columns)\n",
    "  t_relevance = {}\n",
    "  relevance = {}\n",
    "  threshold_value_index = math.floor( math.sqrt(m) * math.log(m,10) )\n",
    "  for i in range (len(columns)):\n",
    "#     t_relevance[ (columns[i], class_label) ] = calculate_symmetric_uncertainity (df, columns[i], class_label)\n",
    "#     t_relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_without_normalization(df, columns[i], class_label)\n",
    "    t_relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, columns[i], class_label)\n",
    "#     relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_without_normalization(df, columns[i], class_label)\n",
    "#     relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, columns[i], class_label)\n",
    "  \n",
    "  # take a temporary dictionary without changing t_relevance dictionary to rank it from large to small value\n",
    "  ranked_t_relevance = OrderedDict(sorted(t_relevance.items(),reverse=True, key=itemgetter(1)))\n",
    "#   print(\"Rank index : \", threshold_value_index )\n",
    "  # print(\"Threshold value : \", list(ranked_t_relevance.values())[threshold_value_index] )\n",
    "\n",
    "  return t_relevance, list(ranked_t_relevance.values())[threshold_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_threshold_value_with_max_entropy_normalization_new(df, columns, class_label):\n",
    "  # m= number of features in the dataset\n",
    "  m = len(columns)\n",
    "  t_relevance = {}\n",
    "  relevance = {}\n",
    "  threshold_value_index = math.floor( math.sqrt(m) * math.log(m,10) )\n",
    "  for i in range (len(columns)):\n",
    "    t_relevance[ (columns[i], class_label) ] = calculate_relevance_or_redundance_value_bias_corrected_with_max_entropy_normalization_new(df, columns[i], class_label)\n",
    "  \n",
    "  # take a temporary dictionary without changing t_relevance dictionary to rank it from large to small value\n",
    "  ranked_t_relevance = OrderedDict(sorted(t_relevance.items(),reverse=True, key=itemgetter(1)))\n",
    "  print(\"Rank index : \", threshold_value_index )\n",
    "  # print(\"Threshold value : \", list(ranked_t_relevance.values())[threshold_value_index] )\n",
    "\n",
    "  return t_relevance, list(ranked_t_relevance.values())[threshold_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_feature_using_t_relevance_critical_value_for_max_entropy_normalization_new(df,t_relevance):\n",
    "  N = df.shape[0]\n",
    "  selected_feature_subset = []\n",
    "  for key, value in t_relevance.items():\n",
    "    critical_val = calculate_critical_value_for_max_entropy_normalization_new(df, key[0], key[1], N)\n",
    "#     print(key, \" -->> Rel val : \", value, \" critical_val: \", critical_val, \" sample size \", N)\n",
    "    if value > critical_val :\n",
    "      feature_name = key[0]\n",
    "#       print(\"Feature added to candidate feature list\")\n",
    "      # print(key, key[0])\n",
    "      selected_feature_subset.append(feature_name)\n",
    "  return selected_feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_feature_list(t_relevance, feature_list, class_label):\n",
    "    unsorted_feature_list = {}\n",
    "    for feature in feature_list:\n",
    "        unsorted_feature_list[feature] = t_relevance[(feature,class_label)]\n",
    "    sorted_feature_list = OrderedDict(sorted(unsorted_feature_list.items(),reverse=True, key=itemgetter(1)))\n",
    "    return sorted_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_JMI_Chi_value_bias_corrected_without_normalization(df, candidate_feature, selected_feature_list, class_label):\n",
    "    relevance_val = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, candidate_feature, class_label)\n",
    "    redundance_list = []\n",
    "    complementary_list = []\n",
    "    for feature in selected_feature_list:\n",
    "        redundance_val = calculate_relevance_or_redundance_value_bias_corrected_without_normalization(df, candidate_feature, feature)\n",
    "        complementary_val = calculate_complementary_information_value_bias_corrected_without_normalization(df, candidate_feature, feature, class_label)\n",
    "        redundance_list.append( redundance_val )\n",
    "        complementary_list.append( complementary_val )\n",
    "    return relevance_val, np.mean(np.array(redundance_list)), ( relevance_val + np.mean(np.array(complementary_list)) - np.mean(np.array(redundance_list)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_pair(selected_feature_subset):\n",
    "  all_pair = []\n",
    "#   pair_dic dictionary to avoid both (1,2) and (2,1) computing\n",
    "#   it will add one tuple from (1,2) and (2,1) in all_pair_with_df\n",
    "#   in this case it will compute half feature pair\n",
    "  pair_dic ={}\n",
    "  for i in selected_feature_subset:\n",
    "    for j in selected_feature_subset:\n",
    "      if i != j :\n",
    "        if (j, i) in pair_dic:\n",
    "          pair_dic[ (i, j) ] = pair_dic[ (j, i) ]\n",
    "          continue\n",
    "        \n",
    "        pair = (i,j)\n",
    "        pair_dic[ (i, j) ] = 1\n",
    "        all_pair.append(pair)\n",
    "  \n",
    "  return all_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mi(pair):\n",
    "  global df_for_parallel\n",
    "  from pyitlib import discrete_random_variable as drv\n",
    "  import numpy as np\n",
    "\n",
    "  i, j = pair\n",
    "#   val = ( 2*drv.information_mutual(df_for_parallel[i].values.astype(np.int32), df_for_parallel[j].values.astype(np.int32)) ) / ( drv.entropy(df_for_parallel[i].values.astype(np.int32)) + drv.entropy(df_for_parallel[j].values.astype(np.int32)) )\n",
    "  x_N = np.unique(df_for_parallel[i].values.astype(np.int32)).size\n",
    "  y_N = np.unique(df_for_parallel[j].values.astype(np.int32)).size\n",
    "  N = df_for_parallel.shape[0]\n",
    "  mi_bias_corrected_with_max_entropy_new = ( (0.69314718056 / np.log(N)) * drv.information_mutual(df_for_parallel[i].values.astype(np.int32), df_for_parallel[j].values.astype(np.int32)) ) - ( ((x_N-1)*(y_N-1)) / (2*N*np.log(N)) )\n",
    "  return (i,j), mi_bias_corrected_with_max_entropy_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initpool(discretized_df):\n",
    "  global df_for_parallel\n",
    "  df_for_parallel = discretized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_relevance_of_a_cluster(t_relevance, one_cluster_features, class_label):\n",
    "  relevance_val_list = []\n",
    "  for i in one_cluster_features:\n",
    "    relevance_val_list.append(t_relevance[(i, class_label)])\n",
    "  mean_relevance_val = np.mean(np.array(relevance_val_list))\n",
    "#   print(\"mean_relevance_val -> \", mean_relevance_val)\n",
    "  return mean_relevance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_redundance_of_a_cluster(f_correlation, one_cluster_features):\n",
    "  redundance_val_list = []\n",
    "  for i in one_cluster_features:\n",
    "    for j in one_cluster_features:\n",
    "      if i != j :\n",
    "        redundance_val_list.append(f_correlation[(i, j)])\n",
    "  mean_redundance_val = np.mean(np.array(redundance_val_list))\n",
    "#   print(\"mean_redundance_val -> \", mean_redundance_val)\n",
    "  return mean_redundance_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_mean_redundance_of_left_and_right_cluster(f_correlation, left_side_cluster, right_side_cluster, root_cluster_length):\n",
    "  left_cluster_mean_redundance = 0\n",
    "  right_cluster_mean_redundance = 0\n",
    "  left_cluster_length = len(left_side_cluster)\n",
    "  right_cluster_length = len(right_side_cluster)\n",
    "#   left_plus_right_cluster_length = left_cluster_length + right_cluster_length\n",
    "\n",
    "  if left_cluster_length > 1 :\n",
    "    left_cluster_mean_redundance = ( left_cluster_length / root_cluster_length ) * calculate_mean_redundance_of_a_cluster(f_correlation, left_side_cluster)\n",
    "  if right_cluster_length > 1 :\n",
    "    right_cluster_mean_redundance = ( right_cluster_length / root_cluster_length ) * calculate_mean_redundance_of_a_cluster(f_correlation, right_side_cluster)\n",
    "\n",
    "  return left_cluster_mean_redundance, right_cluster_mean_redundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clusters_to_get_final_subset_of_features_with_representative_feature_only(t_relevance, final_clusters):\n",
    "  final_selected_feature_list = []\n",
    "  print(\"Selecting Representative feature from each cluster -->>\")\n",
    "\n",
    "  for cluster in final_clusters:\n",
    "    sorted_feature_list = list (get_sorted_feature_list(t_relevance, cluster, '0') )\n",
    "    final_selected_feature_list.append(sorted_feature_list[0])\n",
    "\n",
    "  # print(\"final selected feature length is \",len(final_selected_feature_list))\n",
    "  # print('features are ', final_selected_feature_list)\n",
    "  return final_selected_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clusters_to_get_final_subset_of_features_with_JMI_NN(df, N, final_clusters, feature_list):\n",
    "  t_relevance, threshold_value = select_threshold_value(df, feature_list, '0')\n",
    "  final_selected_feature_list = []\n",
    "  print(\"Selecting features from each cluster -->>\")\n",
    "  final_selected_feature_with_score_dic = {}\n",
    "\n",
    "  for cluster in final_clusters:\n",
    "    selected_feature_list_from_each_cluster = []\n",
    "    sorted_feature_list = list (get_sorted_feature_list(t_relevance, cluster, '0') )\n",
    "    selected_feature_list_from_each_cluster.append(sorted_feature_list[0])\n",
    "    final_selected_feature_with_score_dic[sorted_feature_list[0]] = t_relevance[ (sorted_feature_list[0], '0') ]\n",
    "    \n",
    "    for feature in sorted_feature_list[1:]:\n",
    "      relevance_critical_value, redundance_critical_value, Rrc_critical_value = calculate_critical_value_using_Rrc_criteria(df, feature, selected_feature_list_from_each_cluster, '0', N)\n",
    "#       relevance_val, jmi_redundance_val, jmi_val = calculate_JMI_Chi_value_without_normalization(df, feature, selected_feature_list_from_each_cluster, '0')\n",
    "      relevance_val, jmi_redundance_val, jmi_val = calculate_JMI_Chi_value_bias_corrected_without_normalization(df, feature, selected_feature_list_from_each_cluster, '0')\n",
    "\n",
    "#       if ( jmi_redundance_val < redundance_critical_value ):\n",
    "#         selected_feature_list_from_each_cluster.append(feature)\n",
    "      if jmi_val > Rrc_critical_value:\n",
    "        selected_feature_list_from_each_cluster.append(feature)\n",
    "        final_selected_feature_with_score_dic[feature] = jmi_val\n",
    "      \n",
    "    print(\"No of representative feature from each cluster : \",len(selected_feature_list_from_each_cluster), \" Actually was \", len(cluster))\n",
    "    final_selected_feature_list.extend(selected_feature_list_from_each_cluster)\n",
    "\n",
    "  # print(\"final selected feature length is \",len(final_selected_feature_list))\n",
    "  # print('features are ', final_selected_feature_list)\n",
    "  sorted_final_selected_feature_with_score_dic = {k: v for k, v in sorted(final_selected_feature_with_score_dic.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "  return final_selected_feature_list, sorted_final_selected_feature_with_score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cluster_splitted_without_empty_cluster(f_correlation ,feature_to_compare, t_relevance_val_feature_to_compare, feature_list_to_compare):\n",
    "#   print(\"CLUSTER SPLITTING ON FEATURE -->> \", feature_to_compare)\n",
    "  left_side_cluster = []\n",
    "  right_side_cluster = []\n",
    "  right_side_cluster.append(feature_to_compare)\n",
    "\n",
    "  for feature in feature_list_to_compare:\n",
    "    val = f_correlation[(feature_to_compare, feature)]\n",
    "    if val < t_relevance_val_feature_to_compare:\n",
    "      left_side_cluster.append(feature)\n",
    "    else:\n",
    "      right_side_cluster.append(feature)\n",
    "\n",
    "  if ( len(left_side_cluster) > 0 ):\n",
    "    return left_side_cluster, right_side_cluster\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_feature_list_from_splitted_clusters_mean_child_red_minus_mean_parent_red_diff(my_dict):\n",
    "  sorted_feature_list_corresponding_to_diff_val = sorted(my_dict,key=lambda k: my_dict[k][2], reverse=True)\n",
    "  return sorted_feature_list_corresponding_to_diff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_feature_list_from_splitted_clusters_mean_child_interaction_minus_mean_parent_interaction_diff(my_dict):\n",
    "  sorted_feature_list_corresponding_to_diff_val = sorted(my_dict,key=lambda k: my_dict[k][2], reverse=True)\n",
    "  return sorted_feature_list_corresponding_to_diff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataframe_with_corresponding_class(df, class_list):\n",
    "  df_collection = {}\n",
    "  for class_id in class_list:\n",
    "    one_df = df.loc[ df['0'] == class_id ]\n",
    "    # print(\"class \", class_id, \" class id type \", type(class_id), type(one_df), one_df.shape[0])\n",
    "    # print(one_df)\n",
    "    df_collection[class_id] = one_df\n",
    "\n",
    "  return df_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dict_with_class_distance_list(class_list):\n",
    "  class_distance_list_dict = {}\n",
    "  for class_id in class_list:\n",
    "    class_distance_list_dict[class_id] = []\n",
    "  return class_distance_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here randomly taken \"number_of_feture_for_cluster_evaluation\" features to compare from a cluster to decide whether a parent cluster should split or not\n",
    "# This one is binary clustering with new splitting condition if after splitting one cluster gets empty \n",
    "# for binary cluster creation we compared f_correlation[(feature_to_compare, adjacent_features)] < t_relevance[(feature_to_compare, '0')]\n",
    "def create_cluster_to_get_final_feature_subset_6(df, N, t_relevance, f_correlation, feature_list):\n",
    "  all_temporary_cluster = []\n",
    "  final_clusters = []\n",
    "  all_temporary_cluster.append( feature_list )\n",
    "  count = 1\n",
    "  \n",
    "  while len(all_temporary_cluster) is not 0 :\n",
    "    # Always take the first cluster for evaluation then remove it from the temporary cluster list\n",
    "    one_cluster_features = all_temporary_cluster[0]\n",
    "    all_temporary_cluster.remove(one_cluster_features)\n",
    "    print(\"ITERATION -> \", count)\n",
    "    \n",
    "    if ( len(one_cluster_features) == 1 ):\n",
    "      final_clusters.append(one_cluster_features)\n",
    "      print(\"INCLUDED in final cluster ONE LENGTH CLUSTER -->> \", one_cluster_features, \"\\n==================================================\")\n",
    "      count += 1\n",
    "      continue\n",
    "    \n",
    "#     sorted_feature_list = list (get_sorted_feature_list(t_relevance, one_cluster_features, '0') )\n",
    "#     left_side_cluster = []\n",
    "#     right_side_cluster = []\n",
    "\n",
    "    feature_left_right_cluster_red_diff_dic ={}\n",
    "    left_side_cluster = []\n",
    "    right_side_cluster = []\n",
    "    sample_feature_list = []\n",
    "    if ( len(one_cluster_features) > number_of_feture_for_cluster_evaluation):\n",
    "      random.seed(4)\n",
    "      sample_feature_list = random.sample(one_cluster_features, number_of_feture_for_cluster_evaluation)\n",
    "    else:\n",
    "      sample_feature_list = one_cluster_features.copy()\n",
    "    \n",
    "#     take average relevance value of a cluster for redundance and relevance value comparison\n",
    "    t_relevance_val_feature_to_compare = calculate_mean_relevance_of_a_cluster(t_relevance, one_cluster_features, '0')\n",
    "\n",
    "    for feature_to_compare in sample_feature_list:\n",
    "      feature_list_to_compare = one_cluster_features.copy()\n",
    "      feature_list_to_compare.remove(feature_to_compare)\n",
    "#       t_relevance_val_feature_to_compare = t_relevance[(feature_to_compare, '0')]\n",
    "\n",
    "      cluster_empty_status = is_cluster_splitted_without_empty_cluster(f_correlation ,feature_to_compare, t_relevance_val_feature_to_compare, feature_list_to_compare)\n",
    "      if ( cluster_empty_status is None ):\n",
    "        continue\n",
    "      else:\n",
    "        left_side_cluster, right_side_cluster = cluster_empty_status[0], cluster_empty_status[1]\n",
    "        root_cluster_length = len(one_cluster_features)\n",
    "        root_cluster_mean_redundance = calculate_mean_redundance_of_a_cluster(f_correlation, one_cluster_features)\n",
    "        left_cluster_mean_redundance, right_cluster_mean_redundance = calculate_weighted_mean_redundance_of_left_and_right_cluster(f_correlation, left_side_cluster, right_side_cluster, root_cluster_length)\n",
    "        left_plus_right_cluster_mean_redundance = left_cluster_mean_redundance + right_cluster_mean_redundance\n",
    "        \n",
    "        if ( ( left_plus_right_cluster_mean_redundance > root_cluster_mean_redundance ) ) :\n",
    "          diff = left_plus_right_cluster_mean_redundance - root_cluster_mean_redundance\n",
    "#           print(\"Child clusters redundance increased by -->> \", diff , ' from parent cluster')\n",
    "#           print(\"left cluster \", left_side_cluster)\n",
    "#           print(\"right cluster \", right_side_cluster)\n",
    "          feature_left_right_cluster_red_diff_dic [feature_to_compare] = ( left_side_cluster, right_side_cluster, diff )\n",
    "#           all_temporary_cluster.append(left_side_cluster)\n",
    "#           all_temporary_cluster.append(right_side_cluster)\n",
    "#         else:\n",
    "#           final_clusters.append(one_cluster_features)\n",
    "#           print(\"INCLUDED in final cluster GREATER THAN ONE LENGTH CLUSTER -->> \", one_cluster_features,\"\\n==================================================\")\n",
    "#         break\n",
    "    if ( len(feature_left_right_cluster_red_diff_dic) > 0 ):\n",
    "      sorted_feature_list_corresponding_to_diff_val = get_sorted_feature_list_from_splitted_clusters_mean_child_red_minus_mean_parent_red_diff(feature_left_right_cluster_red_diff_dic)\n",
    "      left_side_cluster, right_side_cluster, diff_val = feature_left_right_cluster_red_diff_dic[sorted_feature_list_corresponding_to_diff_val[0]]\n",
    "#       print(\"left cluster ADDED IN TMPORARY CLUSTER LIST\", left_side_cluster)\n",
    "#       print(\"right clusterr ADDED IN TMPORARY CLUSTER LIST \", right_side_cluster)\n",
    "#       print(\"It is splitted on -->> \", sorted_feature_list_corresponding_to_diff_val[0], \" feature\")\n",
    "      all_temporary_cluster.append(left_side_cluster)\n",
    "      all_temporary_cluster.append(right_side_cluster)\n",
    "    else:\n",
    "      final_clusters.append(one_cluster_features)\n",
    "      print(\"INCLUDED in final cluster -->> \", one_cluster_features,\"\\n==================================================\")\n",
    "    count += 1\n",
    "\n",
    "  print(\"NUMBER OF CLUSTER: \",len(final_clusters))\n",
    "  myfile.write(\"NUMBER OF CLUSTER: \" + str(len(final_clusters)) + \"\\n\")\n",
    "#   print(final_clusters)\n",
    "# #   final_selected_feature_list = merge_clusters_to_get_final_subset_of_features_with_representative_feature_only(t_relevance, final_clusters)\n",
    "  final_selected_feature_list, final_selected_feature_with_score_dic = merge_clusters_to_get_final_subset_of_features_with_JMI_NN(df, N, final_clusters, feature_list)\n",
    "#   final_selected_feature_list = merge_clusters_to_get_final_subset_of_features_with_JMI_NN_3(df, N, t_relevance, final_clusters)\n",
    "#   final_selected_feature_list = merge_clusters_to_get_final_subset_of_features_with_JMI_NN_2(df, N, final_clusters, feature_list)\n",
    "#   final_selected_feature_list = merge_clusters_to_get_final_subset_of_features_with_JMI_max_entropy_normalization_new(df, N, t_relevance, final_clusters)\n",
    "  return final_selected_feature_list, final_selected_feature_with_score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_selected_features(discretized_df):\n",
    "  new_df= discretized_df.copy()\n",
    "  new_df = new_df.drop(columns='0')\n",
    "  columns =list(new_df.columns)\n",
    "  # print(\"Total Number of features \", len(columns))\n",
    "\n",
    "#   t_relevance, threshold_value = select_threshold_value_base(discretized_df, columns, '0')\n",
    "#   selected_feature_subset = remove_irrelevant_feature(t_relevance, threshold_value)\n",
    "\n",
    "#   t_relevance, threshold_value = select_threshold_value(discretized_df, columns, '0')\n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_t_relevance_critical_value(discretized_df, t_relevance)\n",
    "\n",
    "  t_relevance, threshold_value = select_threshold_value_with_max_entropy_normalization_new(discretized_df, columns, '0')\n",
    "  selected_feature_subset = remove_irrelevant_feature_using_t_relevance_critical_value_for_max_entropy_normalization_new(discretized_df, t_relevance)\n",
    "\n",
    "#   t_relevance, relevance, threshold_value = select_threshold_value_with_max_entropy_normalization(discretized_df, columns, '0')\n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_relevance_critical_value(discretized_df, relevance)\n",
    "\n",
    "#   t_relevance, relevance, threshold_value = select_threshold_value_with_SU(discretized_df, columns, '0')  \n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_relevance_critical_value(discretized_df, relevance)\n",
    "\n",
    "#   t_relevance, relevance, threshold_value = select_threshold_value_t_rel_without_BC_and_rel_with_BC(discretized_df, columns, '0')  \n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_relevance_critical_value(discretized_df, relevance)\n",
    "\n",
    "#   t_relevance, relevance, threshold_value = select_threshold_value_with_min_entropy_normalization(discretized_df, columns, '0')  \n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_relevance_critical_value(discretized_df, relevance)\n",
    "\n",
    "  print(\"T_relevance length is \", len(t_relevance))\n",
    "  print('threshold value : ',threshold_value)\n",
    "\n",
    "  print(\"After removing irrelevant features using critical value \\nLength of selected subset feature length \", len(selected_feature_subset)) \n",
    "  myfile.write(\"After removing irrelevant features using critical value Length of selected subset feature length \"+ str(len(selected_feature_subset)) +\" and features are -->>\\n\" )\n",
    "  myfile.write( str(selected_feature_subset) + \"\\n\" )\n",
    "  irrelevant_feature_storing_file.write( str(selected_feature_subset) + \"\\n\" )\n",
    "#   print(selected_feature_subset)\n",
    "\n",
    "  if len(selected_feature_subset) == 1:\n",
    "    feature_score_dic = {}\n",
    "    feature_score_dic[ selected_feature_subset[0] ] = t_relevance[ (selected_feature_subset[0] , '0') ]\n",
    "    return selected_feature_subset, feature_score_dic\n",
    "\n",
    "#   t_relevance, threshold_value = select_threshold_value_with_max_entropy_normalization_new_with_normalized_mi_distance_based(discretized_df, selected_feature_subset, '0')\n",
    "#   selected_feature_subset = remove_irrelevant_feature_using_t_relevance_critical_value_for_max_entropy_normalization_new(discretized_df, t_relevance)\n",
    "\n",
    "  N = discretized_df.shape[0]\n",
    "#   max_entropy_val = get_max_entropy(discretized_df, selected_feature_subset)\n",
    "#   print(\"max_entropy_val is -->> \",max_entropy_val)\n",
    "\n",
    "  # Connected graph construction  \n",
    "#   G = nx.Graph()\n",
    "  f_correlation = {}\n",
    "  \n",
    "  print(\"Calculating F-correlation values -->>\")\n",
    "#   Connected graph construction time\n",
    "  connected_graph_start_time = time.time()\n",
    "  print(\"Creating All feature pair\")\n",
    "  all_pair = make_all_pair(selected_feature_subset)\n",
    "  print(\"All pair creation done\")\n",
    "\n",
    "#   pool = Pool(processes=(os.cpu_count()-1), initializer=initpool, initargs=(discretized_df,))\n",
    "  pool = Pool(processes=1, initializer=initpool, initargs=(discretized_df,))\n",
    "  print(\"Pool created\")\n",
    "  f_correlation_feature_pair_value_list = pool.map(calculate_mi, all_pair)\n",
    "  print(\"All f_correlation value calculation parallelly done and closing Pool -->>\")\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(\"Pool closed\")\n",
    "#   print(\"f_correlation_feature_pair_value_list length is :\",len(f_correlation_feature_pair_value_list))\n",
    "  for feature_pair_value in f_correlation_feature_pair_value_list:\n",
    "    feature_pair, value = feature_pair_value\n",
    "    reverse_feature_pair = feature_pair[::-1]\n",
    "    f_correlation[feature_pair] = value\n",
    "    f_correlation[reverse_feature_pair] = value\n",
    "  \n",
    "  connected_graph_end_time = time.time()\n",
    "  connected_graph_time_diff = connected_graph_end_time - connected_graph_start_time\n",
    "  print(\"All pair f_correlation value calculation time (PARALLELLY) is: \", connected_graph_time_diff, \"(sec) for (\", len(selected_feature_subset), \"*\",len(selected_feature_subset), \") dimension matrix\" )\n",
    "  myfile.write(\"All pair f_correlation value calculation time (PARALLELLY) is: \"+ str(connected_graph_time_diff) + \"\\n\")\n",
    "#   max_t_relevance_val, min_t_relevance_val = max(t_relevance.values()),min(t_relevance.values())\n",
    "#   max_relevance_val, min_relevance_val = max(relevance.values()),min(relevance.values())\n",
    "#   max_f_correlation_val, min_f_correlation_val = max(f_correlation.values()),min(f_correlation.values())\n",
    "# # #   max_redundance_val, min_redundance_val = max(redundance_val_dic.values()),min(redundance_val_dic.values())\n",
    "#   print(\"T-Relevance max, min -->> \",max_t_relevance_val, min_t_relevance_val)\n",
    "#   print(\"Relevance max, min -->> \",max_relevance_val, min_relevance_val)\n",
    "#   print(\"F-Correlation max, min -->> \",max_f_correlation_val, min_f_correlation_val)\n",
    "# # #   print(\"Redundant max, min -->> \", max_redundance_val, min_redundance_val)\n",
    "\n",
    "  print(\"f_correlation_feature_pair_value_list length is :\",len(f_correlation_feature_pair_value_list))\n",
    "  print(\"F-Correlation Length is -->> \",len(f_correlation))\n",
    "#   print(\"f_correlation_feature_pair_value_list length will be half of length f_correlation\")\n",
    "\n",
    "#   print(\"-------------t_relevance------------\\n\", t_relevance, \"\\n\")\n",
    "#   print(\"-------------f_correlation------------\\n\", f_correlation, \"\\n\")\n",
    "\n",
    "#   print(\"\\nbefore t_relevance=========================\",t_relevance, \"\\n======================================\")\n",
    "#   new_t_relevance_with_max_entropy_normalization =  get_new_t_relevance_value_with_max_entropy_normalization_of_a_cluster(t_relevance, max_entropy_val)\n",
    "#   new_f_correlation_with_max_entropy_normalization = get_new_f_correlation_value_with_max_entropy_normalization_of_a_cluster(f_correlation, max_entropy_val)\n",
    "\n",
    "#   print(\"\\nafter t_relevance=========================\",new_t_relevance_with_max_entropy_normalization, \"\\n======================================\")\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_4(discretized_df, N, new_t_relevance_with_max_entropy_normalization, new_f_correlation_with_max_entropy_normalization, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_8(discretized_df, N, new_t_relevance_with_max_entropy_normalization, new_f_correlation_with_max_entropy_normalization, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_6_1(discretized_df, N, new_t_relevance_with_max_entropy_normalization, new_f_correlation_with_max_entropy_normalization, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_6(discretized_df, N, new_t_relevance_with_max_entropy_normalization, new_f_correlation_with_max_entropy_normalization, selected_feature_subset)\n",
    "\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset(discretized_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_2(discretized_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_4(discretized_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "  final_selected_feature_list, final_selected_feature_with_score_dic = create_cluster_to_get_final_feature_subset_6(discretized_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "#   final_selected_feature_list = create_cluster_to_get_final_feature_subset_7_1(discretized_df, N, t_relevance, f_correlation, selected_feature_subset)\n",
    "  # print(\"final selected feature length is \",len(final_selected_feature_list))\n",
    "  # print(final_selected_feature_list)\n",
    "  f_correlation = {}\n",
    "  return final_selected_feature_list, final_selected_feature_with_score_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2ASpDCC2YJO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uKarf-kt2dOo"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saSD-byW3s-C"
   },
   "outputs": [],
   "source": [
    "def classification_report(cm):\n",
    "\n",
    "  true_pos = np.diag(cm)\n",
    "  false_pos = np.sum(cm, axis=0) - true_pos\n",
    "  false_neg = np.sum(cm, axis=1) - true_pos\n",
    "\n",
    "  precision = true_pos / (true_pos+false_pos)\n",
    "  recall = true_pos / (true_pos + false_neg)\n",
    "  \n",
    "  f1_score = 2/(precision**-1 + recall**-1)\n",
    "  return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0X1Sb6ia_Fm_"
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "# gnb = GaussianNB()\n",
    "# clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "# clf = DT(max_depth =50, max_leaf_nodes=20, random_state=42)\n",
    "# clf = SVC(kernel= 'linear')\n",
    "\n",
    "M = 1\n",
    "N = 10\n",
    "# classifiers = ['linearSVM', 'knn', 'dt','nb', 'rf']\n",
    "# classifiers = ['linearSVM', 'knn', 'knn2', 'knn3', 'knn4', 'knn5', 'dt', 'rf']\n",
    "classifiers = ['linearSVM', 'knn', 'dt']\n",
    "labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'selected_features', 'exec_time(sec)']\n",
    "# labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'roc_auc_score', 'selected_features', 'exec_time(sec)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "N_F0NCA_LOjs",
    "outputId": "4a7715ca-7757-443a-9d88-9cd387dd0e27"
   },
   "outputs": [],
   "source": [
    "# directory = \"../all dataset/csv dataset/sadia apu paper dataset\"\n",
    "# directory = \"../all dataset/csv dataset/from suravi\"\n",
    "# directory = \"../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format\"\n",
    "# directory = \"../all dataset/csv dataset/Five dataset\"\n",
    "# directory = \"../all dataset/csv dataset/GSE gene dataset\"\n",
    "# directory = \"../all dataset/csv dataset/GDS gene dataset\"\n",
    "directory = '../../all dataset/csv dataset/Security_dataset/'\n",
    "datasets = os.listdir(directory)\n",
    "\n",
    "\n",
    "# datasets = os.listdir(directory)\n",
    "# datasets.remove('Lung.csv')\n",
    "# datasets.remove('colon.csv')\n",
    "# datasets.remove('Semeion.csv')\n",
    "\n",
    "# datasets = os.listdir(directory)\n",
    "# datasets.remove('LUNG.csv')\n",
    "# datasets.remove('MLL.csv')\n",
    "# datasets.remove('OVARIAN.csv')\n",
    "\n",
    "# datasets = ['arrhythmia_formatted.csv', 'australian.csv', 'breast.csv', 'Cardio.csv', 'dermatology_formatted.csv', 'glass.csv', 'heart.csv', 'ionosphere.csv']\n",
    "# datasets = ['merged_GDS3341.csv', 'merged_GDS4824.csv']\n",
    "# datasets = ['CNS.csv', 'COLON.csv', 'SRBCT.csv', 'LEUKEMIA.csv', 'LEUKEMIA3C.csv', 'LEUKEMIA4C.csv', 'LYMPHOMA.csv' ]\n",
    "# datasets = ['breast.csv']\n",
    "# datasets = ['merged_GDS3341.csv', 'merged_GDS3858.csv', 'merged_GDS4167.csv', 'merged_GDS4168.csv', 'merged_GDS4824.csv']\n",
    "\n",
    "# datasets = ['dermatology_formatted.csv', 'sonar data lebel first10fold.csv', 'yeast.csv']\n",
    "# datasets = ['CNS.csv', 'COLON.csv', 'LEUKEMIA.csv', 'LEUKEMIA3C.csv', 'LEUKEMIA4C.csv', 'LUNG.csv', 'LYMPHOMA.csv', 'MLL.csv', 'OVARIAN.csv', 'SRBCT.csv']\n",
    "# datasets = ['dermatology_formatted.csv','glass.csv', 'ionosphere.csv', 'iris.csv', 'sonar data lebel first10fold.csv']\n",
    "# datasets = ['merged_GSE106291.csv', 'merged_GSE18842.csv', 'merged_GSE45016.csv', 'merged_GSE55945.csv', 'merged_GSE99095.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "# ['BLCA.csv', 'BRCA.csv', 'CESC.csv', 'LAML.csv', 'LIHC.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ten_fold_feature_set_dic ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5-le9lG_FwH"
   },
   "outputs": [],
   "source": [
    "# per_dataset_result_storing_dir = \"FAST_v6_2_binary_method_base/\"\n",
    "# pickle_file_result_dir = \"FAST_v6_2_binary_method_base_pickle_files/\"\n",
    "\n",
    "# csv_results = []\n",
    "# def produce_result():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "#     dataset_file_name = dataset[:-4]\n",
    "    \n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "    \n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "#     # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "#     # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "#     # print(undiscretized_df.head(3))\n",
    "    \n",
    "#     undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "#     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     # print(\"Discritized Dataframe \\n---------------------\")\n",
    "#     # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "#     # print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "#     # print (X.shape,y.shape, type(X), type(y))\n",
    "#     # print(X.head(3))\n",
    "#     # print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "#     individual_file_all_fold_result_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold.txt\",\"w+\")\n",
    "#     individual_file_all_fold_result_with_score_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold_with_score.txt\",\"w+\")\n",
    "#     pickle_file_result = open(pickle_file_result_dir + dataset_file_name + '.pkl', 'wb')\n",
    "\n",
    "\n",
    "#     kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     if (discretized_df.shape[0] <= 50):\n",
    "#       print('LOOCV')\n",
    "#       kf = LeaveOneOut()\n",
    "    \n",
    "# #     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     skf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     lkf = LeaveOneOut()\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time() \n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(X, y):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "#       ten_fold_feature_set_with_score.append(final_selected_feature_with_score_dic)\n",
    "      \n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "# #         pred_prob = clf.predict_proba(X_test)\n",
    "# #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "# #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "#     individual_file_all_fold_result_file.close()\n",
    "#     individual_file_all_fold_result_with_score_file.close()\n",
    "    \n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "#     pickle.dump(ten_fold_feature_set, pickle_file_result)\n",
    "#     pickle.dump(ten_fold_feature_set_with_score, pickle_file_result)\n",
    "#     pickle_file_result.close()\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_dataset_result_storing_dir = \"FAST_v6_2_binary_method_base/\"\n",
    "pickle_file_result_dir = \"FAST_v6_2_binary_method_base_pickle_files/\"\n",
    "\n",
    "csv_results = []\n",
    "############## for Network dataset #########\n",
    "def produce_result_with_dt_CM():\n",
    "#   csv_results = []\n",
    "  for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "    ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy = []\n",
    "    ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "    file_name = '../../all dataset/csv dataset/Security_dataset/'+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "    # print(\"Discritized Dataframe \\n---------------------\")\n",
    "    # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "    irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "    individual_file_all_fold_result_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold.txt\",\"w+\")\n",
    "    individual_file_all_fold_result_with_score_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold_with_score.txt\",\"w+\")\n",
    "#     pickle_file_result = open(pickle_file_result_dir + dataset_file_name + '.pkl', 'wb')\n",
    "\n",
    "\n",
    "    kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     if (discretized_df.shape[0] <= 50):\n",
    "#       print('LOOCV')\n",
    "#       kf = LeaveOneOut()\n",
    "    \n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     skf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     lkf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "    cm = np.zeros((n_class,n_class))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "      # taking selected features\n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "      # print(one_fold_discretized_df.head(3))\n",
    "      final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "      selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "      ten_fold_feature_set.append(final_selected_feature_list)\n",
    "      ten_fold_feature_set_with_score.append(final_selected_feature_with_score_dic)\n",
    "      \n",
    "      X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "      y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "      \n",
    "      clf = DT(random_state = 42) \n",
    "      clf.fit(X_train, y_train)\n",
    "      Predictions_test = clf.predict(X_test)\n",
    "      true = list(y_test)\n",
    "      pred = list(Predictions_test)\n",
    "      precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "      accuracy = accuracy_score(true, pred)\n",
    "      dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "\n",
    "      cm += confusion_matrix(true, pred)\n",
    "      print(cm)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time \n",
    "#         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "      print(\"\\nDataset: \", dataset ,\", Classifier: DT, Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list), \", Execution time \", one_fold_exec_time_diff)\n",
    "      print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "      \n",
    "      \n",
    "      myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "      myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "      per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      ten_fold_accuracy.append([accuracy])\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df = pd.DataFrame(data=ten_fold_accuracy)\n",
    "    acc_result_df.to_csv (\"FSRC ten fold result/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    individual_file_all_fold_result_file.close()\n",
    "    individual_file_all_fold_result_with_score_file.close()\n",
    "    \n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    \n",
    "    myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "#     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "#     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "#     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "    \n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "       \n",
    "  myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "  return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['nsl_kdd_cat_in_num_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nsl_kdd_cat_in_num_multiclass\n",
    "print(\"nsl_kdd_cat_in_num_multiclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# nsl_kdd_cat_in_num_multiclass\n",
    "print(\"nsl_kdd_cat_in_num_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['nsl_kdd_cat_in_num_binaryclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nsl_kdd_cat_in_num_binaryclass\n",
    "print(\"nsl_kdd_cat_in_num_binaryclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsl_kdd_cat_in_num_binaryclass\n",
    "print(\"nsl_kdd_cat_in_num_binaryclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['unsw_nb_15_cat_in_num_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unsw_nb_15_cat_in_num_multiclass\n",
    "print(\"unsw_nb_15_cat_in_num_multiclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# unsw_nb_15_cat_in_num_multiclass\n",
    "print(\"unsw_nb_15_cat_in_num_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['unsw_nb_15_cat_in_num_binaryclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unsw_nb_15_cat_in_num_binaryclass\n",
    "print(\"unsw_nb_15_cat_in_num_binaryclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary class\n",
    "# unsw_nb_15_cat_in_num_binaryclass\n",
    "print(\"unsw_nb_15_cat_in_num_binaryclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cic_ids_full_multiclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cic_ids_full_multiclass\n",
    "print(\"cic_ids_full_multiclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple class\n",
    "# cic_ids_full_multiclass\n",
    "print(\"cic_ids_full_multiclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cic_ids_full_binaryclass.csv']\n",
    "print(len(datasets),type(datasets), type(datasets[0]))\n",
    "print (datasets)\n",
    "dataset_file_name = datasets[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cic_ids_full_binaryclass\n",
    "print(\"cic_ids_full_binaryclass\")\n",
    "cm = produce_result_with_dt_CM()\n",
    "print(np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary class\n",
    "# cic_ids_full_binaryclass\n",
    "print(\"cic_ids_full_binaryclass\")\n",
    "class_prec, class_rec, class_f1 = classification_report(cm)\n",
    "class_acc = cm.diagonal()/np.sum(cm, axis=1)\n",
    "print('class-wise precision:',class_prec)\n",
    "print('class-wise recall:',class_rec)\n",
    "print('class-wise f1score:',class_f1)\n",
    "print('class-wise accuracy:',class_acc)\n",
    "print(cm.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "ov_FPR = np.sum(FP)/(np.sum(FP)+ np.sum(TN))\n",
    "\n",
    "print('class-wise False Positive Rate: ', FPR)\n",
    "print(\"OVERALL False Positive Rate: \", ov_FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_file_name)\n",
    "class_wise_result = []\n",
    "class_wise_result_label =['dataset', 'precision', 'recall', 'f1_score', 'accuracy', 'FPR']\n",
    "\n",
    "for index, val in enumerate(class_prec):\n",
    "  class_wise_result.append([dataset_file_name, \"{:.2f}\".format(class_prec[index]*100), \"{:.2f}\".format(class_rec[index]*100), \"{:.2f}\".format(class_f1[index]*100), \"{:.2f}\".format(class_acc[index]*100), FPR[index]])\n",
    "\n",
    "class_wise_result_df = pd.DataFrame(data=class_wise_result, columns = class_wise_result_label)\n",
    "class_wise_result_df.to_csv (\"FSRC class wise accuracy result/\"+ dataset_file_name +'_class_wise_result.csv', sep=\",\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1\n",
    "N = 10\n",
    "classifiers = ['linearSVM', 'knn', 'dt']\n",
    "labels = ['dataset', 'classifier', 'precision', 'recall', 'f1score', 'accuracy', 'selected_features', 'exec_time(sec)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_dataset_result_storing_dir = \"FAST_v6_2_binary_method_base/\"\n",
    "pickle_file_result_dir = \"FAST_v6_2_binary_method_base_pickle_files/\"\n",
    "\n",
    "csv_results = []\n",
    "def produce_result_with_robust_mahalanobis_distance_svm_knn_DT():\n",
    "#   csv_results = []\n",
    "  for dataset in datasets:\n",
    "    linearSVM_result_list = []\n",
    "    knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "    ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy_dt = []\n",
    "    ten_fold_accuracy_knn = []\n",
    "    ten_fold_accuracy_svm = []\n",
    "    ten_fold_fscore_dt = []\n",
    "    ten_fold_fscore_knn = []\n",
    "    ten_fold_fscore_svm = []\n",
    "    ten_fold_feature_set_with_score =[]\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     file_name = '../../all dataset/csv dataset/Security_dataset/'+dataset\n",
    "    file_name = \"../../all dataset/csv dataset/Selected dataset/\"+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "    # print(\"Discritized Dataframe \\n---------------------\")\n",
    "    # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "    irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "    individual_file_all_fold_result_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold.txt\",\"w+\")\n",
    "    individual_file_all_fold_result_with_score_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold_with_score.txt\",\"w+\")\n",
    "#     pickle_file_result = open(pickle_file_result_dir + dataset_file_name + '.pkl', 'wb')\n",
    "\n",
    "\n",
    "#     kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     if (discretized_df.shape[0] <= 50):\n",
    "#       print('LOOCV')\n",
    "#       kf = LeaveOneOut()\n",
    "    \n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "    kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "    \n",
    "    n_class = len(undiscretized_df['0'].unique())\n",
    "#     cm = np.zeros((n_class,n_class))\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "      # taking selected features\n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "      # print(one_fold_discretized_df.head(3))\n",
    "      final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "      selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "      ten_fold_feature_set.append(final_selected_feature_list)\n",
    "      ten_fold_feature_set_with_score.append(final_selected_feature_with_score_dic)\n",
    "      \n",
    "      X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "      y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "        \n",
    "      for classifier_name in classifiers:\n",
    "        clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "        if (classifier_name == 'linearSVM'):\n",
    "          clf = SVC(kernel= 'linear', probability = True)\n",
    "#           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "        elif (classifier_name == 'knn'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "        elif (classifier_name == 'knn2'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "        elif (classifier_name == 'knn3'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "        elif (classifier_name == 'knn4'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "        elif (classifier_name == 'knn5'):\n",
    "          clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "        elif (classifier_name == 'dt'):\n",
    "          clf = DT(random_state = 42)\n",
    "        elif (classifier_name == 'rf'):\n",
    "          clf = RF(random_state = 42)\n",
    "      \n",
    "        clf.fit(X_train, y_train)\n",
    "        Predictions_test = clf.predict(X_test)\n",
    "        true = list(y_test)\n",
    "        pred = list(Predictions_test)\n",
    "        precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "        accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "\n",
    "        if (classifier_name == 'linearSVM'):\n",
    "          linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_svm.append([accuracy])\n",
    "          ten_fold_fscore_svm.append([f1score])\n",
    "        elif (classifier_name == 'knn'):\n",
    "          knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_knn.append([accuracy])\n",
    "          ten_fold_fscore_knn.append([f1score])\n",
    "        elif (classifier_name == 'knn2'):\n",
    "          knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn3'):\n",
    "          knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn4'):\n",
    "          knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'knn5'):\n",
    "          knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "        elif (classifier_name == 'dt'):\n",
    "          dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "          ten_fold_accuracy_dt.append([accuracy])\n",
    "          ten_fold_fscore_dt.append([f1score])\n",
    "        elif (classifier_name == 'rf'):\n",
    "          rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "    \n",
    "        print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "        print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time \n",
    "      print(\"Fold: \", fold_no, \"Execution time \", one_fold_exec_time_diff)    \n",
    "#         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#       print(\"\\nDataset: \", dataset ,\", Classifier: DT, Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list), \", Execution time \", one_fold_exec_time_diff)\n",
    "#       print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#       print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "      \n",
    "      per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    acc_result_df_svm = pd.DataFrame(data=ten_fold_accuracy_svm)\n",
    "    acc_result_df_knn = pd.DataFrame(data=ten_fold_accuracy_knn)\n",
    "    acc_result_df_dt = pd.DataFrame(data=ten_fold_accuracy_dt)\n",
    "    acc_result_df_svm.to_csv (\"ten_fold_result/accuracy/svm/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    acc_result_df_knn.to_csv (\"ten_fold_result/accuracy/knn/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    acc_result_df_dt.to_csv (\"ten_fold_result/accuracy/dt/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    fscore_result_df_svm = pd.DataFrame(data=ten_fold_fscore_svm)\n",
    "    fscore_result_df_knn = pd.DataFrame(data=ten_fold_fscore_knn)\n",
    "    fscore_result_df_dt = pd.DataFrame(data=ten_fold_fscore_dt)\n",
    "    fscore_result_df_svm.to_csv (\"ten_fold_result/fscore/svm/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    fscore_result_df_knn.to_csv (\"ten_fold_result/fscore/knn/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    fscore_result_df_dt.to_csv (\"ten_fold_result/fscore/dt/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "  \n",
    "    \n",
    "    individual_file_all_fold_result_file.close()\n",
    "    individual_file_all_fold_result_with_score_file.close()\n",
    "    \n",
    "    linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "    knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "    dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "    print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "    print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "    \n",
    "\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    \n",
    "    myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "\n",
    "    csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], \"{:.2f}\".format(linearSVM_result[2]*100), \"{:.2f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "    csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], \"{:.2f}\".format(knn_result[2]*100), \"{:.2f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "    csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], \"{:.2f}\".format(dt_result[2]*100), \"{:.2f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datasets = ['iris.csv']\n",
    "datasets = ['iris.csv', 'balance.csv', 'mammographic.csv', 'appendicitis.csv', 'ecoli3.csv', 'led7digit.csv', 'pima-indians-diabetes.csv', 'wisconsin.csv', 'heart.csv', 'wine.csv', 'vehicle0.csv', 'hepatitis.csv', 'German.csv', 'thyroid.csv', 'dermatology_formatted.csv', 'landsat.csv', 'spectfheart.csv', 'Spambase.csv', 'sonar data lebel first10fold.csv', 'optdigits.csv', 'movement_libras.csv', 'madelon.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('FSRC svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['COLON.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['SRBCT.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['CNS.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LYMPHOMA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA3C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['LEUKEMIA4C.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "result_df.to_csv ('FSRC svm knn dt.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()\n",
    "irrelevant_feature_storing_file.close()\n",
    "per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['MLL.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['OVARIAN.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = ['LUNG.csv']\n",
    "produce_result_with_robust_mahalanobis_distance_svm_knn_DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_dataset_result_storing_dir = \"FAST_v6_2_binary_method_base/\"\n",
    "# pickle_file_result_dir = \"FAST_v6_2_binary_method_base_pickle_files/\"\n",
    "\n",
    "# csv_results = []\n",
    "# def produce_result_for_plos_one():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     ten_fold_feature_set_with_score =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "#     dataset_file_name = dataset[:-4]\n",
    "    \n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "    \n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "#     # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "#     # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "#     # print(undiscretized_df.head(3))\n",
    "    \n",
    "#     undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "#     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     # print(\"Discritized Dataframe \\n---------------------\")\n",
    "#     # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "#     # print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "#     # print (X.shape,y.shape, type(X), type(y))\n",
    "#     # print(X.head(3))\n",
    "#     # print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "#     individual_file_all_fold_result_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold.txt\",\"w+\")\n",
    "#     individual_file_all_fold_result_with_score_file = open(per_dataset_result_storing_dir + dataset_file_name +\"_per_fold_with_score.txt\",\"w+\")\n",
    "#     pickle_file_result = open(pickle_file_result_dir + dataset_file_name + '.pkl', 'wb')\n",
    "\n",
    "\n",
    "# #     kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     if (discretized_df.shape[0] <= 50):\n",
    "# #       print('LOOCV')\n",
    "# #       kf = LeaveOneOut()\n",
    "    \n",
    "#     kf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=10)\n",
    "    \n",
    "# #     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     skf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     lkf = LeaveOneOut()\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time() \n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(X, y):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "#       ten_fold_feature_set_with_score.append(final_selected_feature_with_score_dic)\n",
    "      \n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "# #         pred_prob = clf.predict_proba(X_test)\n",
    "# #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "# #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       individual_file_all_fold_result_with_score_file.write( str(final_selected_feature_with_score_dic) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "#     individual_file_all_fold_result_file.close()\n",
    "#     individual_file_all_fold_result_with_score_file.close()\n",
    "    \n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "#     pickle.dump(ten_fold_feature_set, pickle_file_result)\n",
    "#     pickle.dump(ten_fold_feature_set_with_score, pickle_file_result)\n",
    "#     pickle_file_result.close()\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# dir = \"FAST_v6_2_binary_method_base_per_fold/\"\n",
    "\n",
    "# def produce_result_with_feature_frequency_top_k_features(k):\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "#     dataset_file_name = dataset[:-4]\n",
    "    \n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "    \n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "#     # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "#     # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "#     # print(undiscretized_df.head(3))\n",
    "    \n",
    "#     undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "#     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     # print(\"Discritized Dataframe \\n---------------------\")\n",
    "#     # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "#     # print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "#     # print (X.shape,y.shape, type(X), type(y))\n",
    "#     # print(X.head(3))\n",
    "#     # print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "#     sorted_feature_list_with_frequency_count = get_feature_list_with_frequency_count(dir, dataset_file_name)\n",
    "    \n",
    "#     if ( len(sorted_feature_list_with_frequency_count) > k):\n",
    "#       sorted_feature_list_with_frequency_count = sorted_feature_list_with_frequency_count[ :k ]\n",
    "\n",
    "\n",
    "# #     kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     if (discretized_df.shape[0] <= 50):\n",
    "# #       print('LOOCV')\n",
    "# #       kf = LeaveOneOut()\n",
    "    \n",
    "# #     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "# #     skf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time() \n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(X, y):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      \n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "# #       final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "      \n",
    "#       final_selected_feature_list = sorted_feature_list_with_frequency_count.copy()\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "\n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "# #         pred_prob = clf.predict_proba(X_test)\n",
    "# #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \",Topmost selected Features with frequency: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "    \n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "       \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ten_fold_feature_list\n",
    "csv_results = []\n",
    "dir = \"FAST_v6_2_binary_method_base/\"\n",
    "\n",
    "def produce_ten_fold_result():\n",
    "  for dataset in datasets:\n",
    "    linearSVM_result_list = []\n",
    "    knn_result_list = []\n",
    "    knn2_result_list = []\n",
    "    knn3_result_list = []\n",
    "    knn4_result_list = []\n",
    "    knn5_result_list = []\n",
    "    dt_result_list = []\n",
    "    rf_result_list = []\n",
    "    \n",
    "    ten_fold_feature_set =[]\n",
    "    ten_fold_accuracy = []\n",
    "    print(\"##############################################\")\n",
    "    print (\"reading dataset: \",dataset)\n",
    "    dataset_file_name = dataset[:-4]\n",
    "    \n",
    "#     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "    file_name = '../all dataset/csv dataset/from suravi/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GDS gene dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "    \n",
    "    undiscretized_df = pd.read_csv (file_name)\n",
    "    print(\"##############################################\")\n",
    "\n",
    "    # print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "    # print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "    # print(undiscretized_df.head(3))\n",
    "    \n",
    "    undiscretized_df = get_df_for_dataset_except_single_value_column(undiscretized_df)\n",
    "\n",
    "    discretized_df = get_discritized_df(undiscretized_df)\n",
    "    # print(\"Discritized Dataframe \\n---------------------\")\n",
    "    # print(discretized_df.shape, len(discretized_df.columns) )\n",
    "    # print(discretized_df.head(3))\n",
    "\n",
    "    X = discretized_df.drop(columns=['0'])\n",
    "    y = discretized_df['0']\n",
    "    # print (X.shape,y.shape, type(X), type(y))\n",
    "    # print(X.head(3))\n",
    "    # print(y.head(3))\n",
    "    \n",
    "    myfile.write( dataset + \"\\n\" )\n",
    "    per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "    \n",
    "    ten_fold_feature_list = get_ten_fold_feature_list(dir, dataset_file_name)\n",
    "    print(ten_fold_feature_list, type(ten_fold_feature_list))\n",
    "\n",
    "#     kf = StratifiedKFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     if (discretized_df.shape[0] <= 50):\n",
    "#       print('LOOCV')\n",
    "#       kf = LeaveOneOut()\n",
    "    \n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle=True, random_state=10)\n",
    "#     kf = LeaveOneOut()\n",
    "    # print(kf.get_n_splits(discretized_df))\n",
    "    start_time = time.time() \n",
    "    selected_featutre_length_list =[]\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "      one_fold_exec_start_time = time.time()\n",
    "      print(\"==========================================\")\n",
    "      # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "      X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "      y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "      # taking selected features\n",
    "      one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "      \n",
    "      # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "      # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list, final_selected_feature_with_score_dic = get_final_selected_features(one_fold_discretized_df)\n",
    "      \n",
    "      final_selected_feature_list = ten_fold_feature_list[fold_no-1]\n",
    "#       print(final_selected_feature_list, type(final_selected_feature_list))\n",
    "    \n",
    "      selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "      ten_fold_feature_set.append(final_selected_feature_list)\n",
    "\n",
    "      X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "      y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "      # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "      # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "    \n",
    "      clf = SVC(kernel= 'linear', probability = True) \n",
    "      clf.fit(X_train, y_train)\n",
    "      Predictions_test = clf.predict(X_test)\n",
    "      true = list(y_test)\n",
    "      pred = list(Predictions_test)\n",
    "      precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "      accuracy = accuracy_score(true, pred)\n",
    "      \n",
    "      print(\"\\nDataset: \", dataset ,\", Classifier: linearSVM, Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "      print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "    \n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "# #         pred_prob = clf.predict_proba(X_test)\n",
    "# #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "      one_fold_exec_end_time = time.time()\n",
    "      one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "      print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "      print(final_selected_feature_list)\n",
    "      \n",
    "      myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \",Topmost selected Features with frequency: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "      myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "        \n",
    "      ten_fold_accuracy.append([accuracy])\n",
    "      \n",
    "      fold_no +=1\n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    \n",
    "    acc_result_df = pd.DataFrame(data=ten_fold_accuracy)\n",
    "    # result_df.to_csv ('result_with_FAST_JMI_Chi.csv', sep=\",\", index=None)\n",
    "    acc_result_df.to_csv (\"FAST_v6_2_binary_method_base_ten_fold_result/\"+ dataset_file_name +'_ten_fold.csv', sep=\",\", header=None, index=None)\n",
    "    \n",
    "    linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "    #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "    average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    print(\"result of dataset: \", dataset,\" linearSVM_result acc \", accuracy)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "\n",
    "#     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "#     print(\"Overall Test precision \", ov_precision)\n",
    "#     print(\"Overall Test recall \", ov_recall)\n",
    "#     print(\"Overall Test f1-score \", ov_f1score)\n",
    "#     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "    print(\"On average selected features are: \", average_selected_feature)\n",
    "    print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "    print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "    myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "#     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "#     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "#     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "    dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "       \n",
    "  myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "produce_ten_fold_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ten_fold_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()\n",
    "irrelevant_feature_storing_file.close()\n",
    "per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# def produce_result_with_auc():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "# #     print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "# #     print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "# #     print(undiscretized_df.head(3))\n",
    "\n",
    "#     discretized_df = get_discritized_df(undiscretized_df)\n",
    "# #     print(\"Discritized Dataframe \\n---------------------\")\n",
    "# #     print(discretized_df.shape, len(discretized_df.columns) )\n",
    "# #     print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "# #     print(\"After descritization X and Y\")\n",
    "# #     print (X.shape,y.shape, type(X), type(y))\n",
    "# #     print(X.head(3))\n",
    "# #     print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "\n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time()\n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(discretized_df):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "# #       print(\"one fold discretized data X_train\\n\",X_train.head(3))\n",
    "# #       print(\"one fold discretized data X_test\\n\",X_test.head(3))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list = get_final_selected_features(one_fold_discretized_df)\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "      \n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(n_estimators = 300, random_state = 42)\n",
    "# #           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "# #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "\n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), linearSVM_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), knn_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), knn2_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), knn3_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), knn4_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), knn5_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), dt_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), rf_result[4], average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "    \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# def produce_result_with_plos_one_discritization_model_train_test_with_real_data():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "# #     print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "# #     print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "# #     print(undiscretized_df.head(3))\n",
    "\n",
    "#     discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# #     print(\"Discritized Dataframe \\n---------------------\")\n",
    "# #     print(discretized_df.shape, len(discretized_df.columns) )\n",
    "# #     print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "# #     print(\"After descritization X and Y\")\n",
    "# #     print (X.shape,y.shape, type(X), type(y))\n",
    "# #     print(X.head(3))\n",
    "# #     print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "\n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time()\n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(discretized_df):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "# #       print(\"one fold discretized data X_train\\n\",X_train.head(3))\n",
    "# #       print(\"one fold discretized data X_test\\n\",X_test.head(3))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list = get_final_selected_features(one_fold_discretized_df)\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "      \n",
    "#       # Model Train test with Real Data\n",
    "#       X_train, X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "#       y_train, y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "# #       print(\"one fold real data X_train\\n\",X_train.head(3))\n",
    "# #       print(\"one fold real data X_test\\n\",X_test.head(3))\n",
    "      \n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "# #       print(\"real data X_train test after feature selection\\n\",X_train[0], X_test[0])\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "# #         pred_prob = clf.predict_proba(X_test)\n",
    "# #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "# #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "\n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "    \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# def produce_result_with_plos_one_discritization_model_train_test_with_real_data_with_auc():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "# #     print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "# #     print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "# #     print(undiscretized_df.head(3))\n",
    "\n",
    "# #     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# #     print(\"Discritized Dataframe \\n---------------------\")\n",
    "# #     print(discretized_df.shape, len(discretized_df.columns) )\n",
    "# #     print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "# #     print(\"After descritization X and Y\")\n",
    "# #     print (X.shape,y.shape, type(X), type(y))\n",
    "# #     print(X.head(3))\n",
    "# #     print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "\n",
    "#     kf = KFold(n_splits = N, shuffle=True, random_state=10)\n",
    "#     # print(kf.get_n_splits(discretized_df))\n",
    "#     start_time = time.time()\n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for train_index, test_index in kf.split(discretized_df):\n",
    "#       one_fold_exec_start_time = time.time()\n",
    "#       print(\"==========================================\")\n",
    "#       # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "# #       print(\"one fold discretized data X_train\\n\",X_train.head(3))\n",
    "# #       print(\"one fold discretized data X_test\\n\",X_test.head(3))\n",
    "\n",
    "#       # taking selected features\n",
    "#       one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#       # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#       # print(one_fold_discretized_df.head(3))\n",
    "#       final_selected_feature_list = get_final_selected_features(one_fold_discretized_df)\n",
    "#       selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#       ten_fold_feature_set.append(final_selected_feature_list)\n",
    "      \n",
    "#       # Model Train test with Real Data\n",
    "#       X_train, X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "#       y_train, y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "# #       print(\"one fold real data X_train\\n\",X_train.head(3))\n",
    "# #       print(\"one fold real data X_test\\n\",X_test.head(3))\n",
    "#       X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#       y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "# #       print(\"real data X_train test after feature selection\\n\",X_train[0], X_test[0])\n",
    "#       # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#       # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#       for classifier_name in classifiers:\n",
    "#         clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           clf = SVC(kernel= 'linear', probability = True)\n",
    "# #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           clf = DT(random_state = 42)\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           clf = RF(random_state = 42)\n",
    "        \n",
    "#         clf.fit(X_train, y_train)\n",
    "#         Predictions_test = clf.predict(X_test)\n",
    "#         true = list(y_test)\n",
    "#         pred = list(Predictions_test)\n",
    "#         precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#         accuracy = accuracy_score(true, pred)\n",
    "        \n",
    "#         pred_prob = clf.predict_proba(X_test)\n",
    "#         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "        \n",
    "#         if (classifier_name == 'linearSVM'):\n",
    "#           linearSVM_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn'):\n",
    "#           knn_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn2'):\n",
    "#           knn2_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn3'):\n",
    "#           knn3_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn4'):\n",
    "#           knn4_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'knn5'):\n",
    "#           knn5_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'dt'):\n",
    "#           dt_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#         elif (classifier_name == 'rf'):\n",
    "#           rf_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "# #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#         print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "# #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#       one_fold_exec_end_time = time.time()\n",
    "#       one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#       print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#       print(final_selected_feature_list)\n",
    "      \n",
    "#       myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#       myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "# #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#       per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "      \n",
    "#       fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "\n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), linearSVM_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), knn_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), knn2_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), knn3_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), knn4_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), knn5_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), dt_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), rf_result[4], average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "    \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# def produce_result_with_plos_one_discritization_model_train_test_with_real_data_10_times_5_fold():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "# #     print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "# #     print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "# #     print(undiscretized_df.head(3))\n",
    "\n",
    "# #     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# #     print(\"Discritized Dataframe \\n---------------------\")\n",
    "# #     print(discretized_df.shape, len(discretized_df.columns) )\n",
    "# #     print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "# #     print(\"After descritization X and Y\")\n",
    "# #     print (X.shape,y.shape, type(X), type(y))\n",
    "# #     print(X.head(3))\n",
    "# #     print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for i in range(0, 20, 2):\n",
    "#       kf = KFold(n_splits = 5, shuffle=True, random_state = i+10)\n",
    "#       print(\"SHUFFLING========================SHUFFLING========================SHUFFLING  Fold No: \", fold_no)\n",
    "#       for train_index, test_index in kf.split(discretized_df):\n",
    "#         one_fold_exec_start_time = time.time()\n",
    "#         print(\"==========================================\")\n",
    "#         # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#         # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#         # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#   #       print(\"one fold discretized data X_train\\n\",X_train.head(3))\n",
    "#   #       print(\"one fold discretized data X_test\\n\",X_test.head(3))\n",
    "\n",
    "#         # taking selected features\n",
    "#         one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#         # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#         # print(one_fold_discretized_df.head(3))\n",
    "#         final_selected_feature_list = get_final_selected_features(one_fold_discretized_df)\n",
    "#         selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#         ten_fold_feature_set.append(final_selected_feature_list)\n",
    "        \n",
    "#         # Model Train test with Real Data\n",
    "#         X_train, X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "#         y_train, y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "#   #       print(\"one fold real data X_train\\n\",X_train.head(3))\n",
    "#   #       print(\"one fold real data X_test\\n\",X_test.head(3))\n",
    "        \n",
    "#         X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#         y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#   #       print(\"real data X_train test after feature selection\\n\",X_train[0], X_test[0])\n",
    "#         # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#         # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#         for classifier_name in classifiers:\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#           if (classifier_name == 'linearSVM'):\n",
    "#             clf = SVC(kernel= 'linear', probability = True)\n",
    "#   #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#           elif (classifier_name == 'knn'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#           elif (classifier_name == 'knn2'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#           elif (classifier_name == 'knn3'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#           elif (classifier_name == 'knn4'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#           elif (classifier_name == 'knn5'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             clf = DT(random_state = 42)\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             clf = RF(random_state = 42)\n",
    "          \n",
    "#           clf.fit(X_train, y_train)\n",
    "#           Predictions_test = clf.predict(X_test)\n",
    "#           true = list(y_test)\n",
    "#           pred = list(Predictions_test)\n",
    "#           precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#           accuracy = accuracy_score(true, pred)\n",
    "          \n",
    "#   #         pred_prob = clf.predict_proba(X_test)\n",
    "#   #         auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "          \n",
    "#           if (classifier_name == 'linearSVM'):\n",
    "#             linearSVM_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'knn'):\n",
    "#             knn_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'knn2'):\n",
    "#             knn2_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'knn3'):\n",
    "#             knn3_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'knn4'):\n",
    "#             knn4_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'knn5'):\n",
    "#             knn5_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             dt_result_list.append([precision,recall,f1score,accuracy])\n",
    "#           elif (classifier_name == 'rf'):\n",
    "#             rf_result_list.append([precision,recall,f1score,accuracy])\n",
    "#   #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#           print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#           print('precision, recall, f1-score, accuracy -->> ',precision,recall,f1score,accuracy)\n",
    "#   #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#         one_fold_exec_end_time = time.time()\n",
    "#         one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#         print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#         print(final_selected_feature_list)\n",
    "        \n",
    "#         myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#         myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#   #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#         per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "        \n",
    "#         fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "\n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "    \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_results = []\n",
    "# def produce_result_with_plos_one_discritization_model_train_test_with_real_data_with_auc_10_times_5_fold():\n",
    "# #   csv_results = []\n",
    "#   for dataset in datasets:\n",
    "#     linearSVM_result_list = []\n",
    "#     knn_result_list = []\n",
    "#     knn2_result_list = []\n",
    "#     knn3_result_list = []\n",
    "#     knn4_result_list = []\n",
    "#     knn5_result_list = []\n",
    "#     dt_result_list = []\n",
    "#     rf_result_list = []\n",
    "    \n",
    "#     ten_fold_feature_set =[]\n",
    "#     print(\"##############################################\")\n",
    "#     print (\"reading dataset: \",dataset)\n",
    "# #     file_name = '../all dataset/csv dataset/sadia apu paper dataset/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+dataset\n",
    "# #     file_name = '../all dataset/csv dataset/Five dataset/'+dataset\n",
    "#     file_name = '../all dataset/csv dataset/GSE gene dataset/'+dataset\n",
    "#     undiscretized_df = pd.read_csv (file_name)\n",
    "#     print(\"##############################################\")\n",
    "\n",
    "# #     print(\"Undiscritized Dataframe \\n---------------------\")\n",
    "# #     print(undiscretized_df.shape, len(undiscretized_df.columns) )\n",
    "# #     print(undiscretized_df.head(3))\n",
    "\n",
    "# #     discretized_df = get_discritized_df(undiscretized_df)\n",
    "#     discretized_df = get_discritized_df_for_plos_one(undiscretized_df)\n",
    "# #     print(\"Discritized Dataframe \\n---------------------\")\n",
    "# #     print(discretized_df.shape, len(discretized_df.columns) )\n",
    "# #     print(discretized_df.head(3))\n",
    "\n",
    "#     X = discretized_df.drop(columns=['0'])\n",
    "#     y = discretized_df['0']\n",
    "# #     print(\"After descritization X and Y\")\n",
    "# #     print (X.shape,y.shape, type(X), type(y))\n",
    "# #     print(X.head(3))\n",
    "# #     print(y.head(3))\n",
    "    \n",
    "#     myfile.write( dataset + \"\\n\" )\n",
    "#     irrelevant_feature_storing_file.write( dataset + \"\\n\" )\n",
    "#     per_fold_feature_storing_file.write( dataset + \"\\n\" )\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     selected_featutre_length_list =[]\n",
    "#     fold_no = 1\n",
    "#     for i in range(0, 20, 2):\n",
    "#       kf = KFold(n_splits = 5, shuffle=True, random_state = i+10)\n",
    "#       print(\"SHUFFLING========================SHUFFLING========================SHUFFLING  Fold No: \", fold_no)\n",
    "#       for train_index, test_index in kf.split(discretized_df):\n",
    "#         one_fold_exec_start_time = time.time()\n",
    "#         print(\"==========================================\")\n",
    "#         # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#         # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#         # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#   #       print(\"one fold discretized data X_train\\n\",X_train.head(3))\n",
    "#   #       print(\"one fold discretized data X_test\\n\",X_test.head(3))\n",
    "\n",
    "#         # taking selected features\n",
    "#         one_fold_discretized_df = pd.concat([y_train, X_train], axis=1)\n",
    "#         # print(type(one_fold_discretized_df), one_fold_discretized_df.shape)\n",
    "#         # print(one_fold_discretized_df.head(3))\n",
    "#         final_selected_feature_list = get_final_selected_features(one_fold_discretized_df)\n",
    "#         selected_featutre_length_list.append(len(final_selected_feature_list))\n",
    "#         ten_fold_feature_set.append(final_selected_feature_list)\n",
    "        \n",
    "#         # Model Train test with Real Data\n",
    "#         X_train, X_test = undiscretized_df.drop(columns=['0']).iloc[train_index], undiscretized_df.drop(columns=['0']).iloc[test_index]\n",
    "#         y_train, y_test = undiscretized_df['0'].iloc[train_index], undiscretized_df['0'].iloc[test_index]\n",
    "#   #       print(\"one fold real data X_train\\n\",X_train.head(3))\n",
    "#   #       print(\"one fold real data X_test\\n\",X_test.head(3))\n",
    "#         X_train, X_test = X_train[final_selected_feature_list].values.astype(float), X_test[final_selected_feature_list].values.astype(float)\n",
    "#         y_train, y_test = y_train.values.astype(int), y_test.values.astype(int)\n",
    "#   #       print(\"real data X_train test after feature selection\\n\",X_train[0], X_test[0])\n",
    "#         # print (X_train.shape,X_test.shape, y_train.shape, y_test.shape)\n",
    "#         # print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "#         for classifier_name in classifiers:\n",
    "#           clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#           if (classifier_name == 'linearSVM'):\n",
    "#             clf = SVC(kernel= 'linear', probability = True)\n",
    "#   #           clf = LinearSVC(penalty='l2', loss='hinge', C=1, random_state=42)\n",
    "#           elif (classifier_name == 'knn'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=1, weights='uniform')\n",
    "#           elif (classifier_name == 'knn2'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "#           elif (classifier_name == 'knn3'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "#           elif (classifier_name == 'knn4'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "#           elif (classifier_name == 'knn5'):\n",
    "#             clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             clf = DT(random_state = 42)\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             clf = RF(random_state = 42)\n",
    "          \n",
    "#           clf.fit(X_train, y_train)\n",
    "#           Predictions_test = clf.predict(X_test)\n",
    "#           true = list(y_test)\n",
    "#           pred = list(Predictions_test)\n",
    "#           precision, recall, f1score, _ = precision_recall_fscore_support(true, pred, average='weighted')  \n",
    "#           accuracy = accuracy_score(true, pred)\n",
    "          \n",
    "#           pred_prob = clf.predict_proba(X_test)\n",
    "#           auc_score = roc_auc_score(true, pred_prob[:,1])\n",
    "          \n",
    "#           if (classifier_name == 'linearSVM'):\n",
    "#             linearSVM_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'knn'):\n",
    "#             knn_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'knn2'):\n",
    "#             knn2_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'knn3'):\n",
    "#             knn3_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'knn4'):\n",
    "#             knn4_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'knn5'):\n",
    "#             knn5_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'dt'):\n",
    "#             dt_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#           elif (classifier_name == 'rf'):\n",
    "#             rf_result_list.append([precision,recall,f1score,accuracy,auc_score])\n",
    "#   #         myfile.write(\"Dataset: \"+ dataset +\", Classifier: \"+ classifier_name +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\"\\n\")\n",
    "#           print(\"\\nDataset: \", dataset ,\", Classifier: \", classifier_name ,\", Fold: \", fold_no, \", Selected Features: \",len(final_selected_feature_list))\n",
    "#           print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#   #         print('precision, recall, f1-score, accuracy, roc_auc_score',precision,recall,f1score,accuracy,auc_score)\n",
    "#         one_fold_exec_end_time = time.time()\n",
    "#         one_fold_exec_time_diff = one_fold_exec_end_time - one_fold_exec_start_time\n",
    "#         print(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec) and selected features are -->>\\n\")\n",
    "#         print(final_selected_feature_list)\n",
    "        \n",
    "#         myfile.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list))+ \", Execution time \"+ str(one_fold_exec_time_diff) +\" (sec)\"+ \" and selected features are -->>\\n\")\n",
    "#         myfile.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "#   #       feature_storing_file.write(\"Dataset: \"+ dataset +\", Fold: \" +str(fold_no)+ \", Selected Features: \"+ str(len(final_selected_feature_list)) +\" and selected features are -->>\\n\")\n",
    "#         per_fold_feature_storing_file.write( str(final_selected_feature_list) + \"\\n\" )\n",
    "        \n",
    "#         fold_no +=1\n",
    "#     end_time = time.time()\n",
    "#     time_diff = end_time - start_time\n",
    "\n",
    "#     linearSVM_result = np.mean(np.array(linearSVM_result_list), axis=0)\n",
    "#     knn_result = np.mean(np.array(knn_result_list), axis=0)\n",
    "#     knn2_result = np.mean(np.array(knn2_result_list), axis=0)\n",
    "#     knn3_result = np.mean(np.array(knn3_result_list), axis=0)\n",
    "#     knn4_result = np.mean(np.array(knn4_result_list), axis=0)\n",
    "#     knn5_result = np.mean(np.array(knn5_result_list), axis=0)\n",
    "#     dt_result = np.mean(np.array(dt_result_list), axis=0)\n",
    "#     rf_result = np.mean(np.array(rf_result_list), axis=0)\n",
    "#     #ov_accuracy = np.mean(np.array(test_accuracies))\n",
    "#     average_selected_feature = np.mean(np.array(selected_featutre_length_list))\n",
    "    \n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     print(\"result of dataset: \", dataset,\" linearSVM_result \", linearSVM_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn_result \", knn_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn2_result \", knn2_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn3_result \", knn3_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn4_result \", knn4_result)\n",
    "#     print(\"result of dataset: \", dataset,\" knn5_result \", knn5_result)\n",
    "#     print(\"result of dataset: \", dataset,\" dt_result \", dt_result)\n",
    "#     print(\"result of dataset: \", dataset,\" rf_result \", rf_result)\n",
    "# #     print(\"result of dataset: \", dataset, \" classifier: \", classifier_name)\n",
    "# #     print(\"Overall Test precision \", ov_precision)\n",
    "# #     print(\"Overall Test recall \", ov_recall)\n",
    "# #     print(\"Overall Test f1-score \", ov_f1score)\n",
    "# #     print(\"Overall Test accuracy \", ov_accuracy)\n",
    "#     print(\"On average selected features are: \", average_selected_feature)\n",
    "#     print(\"Total Execition time is: \", time_diff, \"(sec)\")\n",
    "#     print(\"//////////////////////////////////////////////////////////\\n\")\n",
    "#     myfile.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature)+ \" Total Execition time \"+ str(time_diff) + \" (sec)\\n--------------------------------------------------\\n\" )\n",
    "# #     feature_storing_file.write(\"Dataset: \"+ dataset +\" On AVERAGE selected features are: \"+ str(average_selected_feature) + \"\\n\")\n",
    "# #     ov_accuracy = \"{:.3f}\".format(ov_accuracy*100)\n",
    "# #     result = [dataset, classifier_name, ov_precision, ov_recall, ov_f1score, ov_accuracy, average_selected_feature, time_diff]\n",
    "#     csv_results.append([dataset, \"linearSVM\", linearSVM_result[0], linearSVM_result[1], linearSVM_result[2], \"{:.3f}\".format(linearSVM_result[3]*100), linearSVM_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=1)\", knn_result[0], knn_result[1], knn_result[2], \"{:.3f}\".format(knn_result[3]*100), knn_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=2)\", knn2_result[0], knn2_result[1], knn2_result[2], \"{:.3f}\".format(knn2_result[3]*100), knn2_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=3)\", knn3_result[0], knn3_result[1], knn3_result[2], \"{:.3f}\".format(knn3_result[3]*100), knn3_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=4)\", knn4_result[0], knn4_result[1], knn4_result[2], \"{:.3f}\".format(knn4_result[3]*100), knn4_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"knn(k=5)\", knn5_result[0], knn5_result[1], knn5_result[2], \"{:.3f}\".format(knn5_result[3]*100), knn5_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"DT\", dt_result[0], dt_result[1], dt_result[2], \"{:.3f}\".format(dt_result[3]*100), dt_result[4], average_selected_feature, time_diff])\n",
    "#     csv_results.append([dataset, \"RF\", rf_result[0], rf_result[1], rf_result[2], \"{:.3f}\".format(rf_result[3]*100), rf_result[4], average_selected_feature, time_diff])\n",
    "  \n",
    "#     dataset_ten_fold_feature_set_dic[dataset] = ten_fold_feature_set\n",
    "    \n",
    "#   myfile.write( \"\\n\\n\"+ str(dataset_ten_fold_feature_set_dic))  \n",
    "# #   return csv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chi_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula,\n",
    "# CG_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, binary_cluster,\n",
    "# redundant_cluster_check_with_child_cluster_mean_red_greater_than_parent_cluster_mean_redundance_randomly_taken_10_features,\n",
    "# JMI with condition jmi_greater_than_jmi_critical_val BC\n",
    "# (create_cluster_to_get_final_feature_subset_6 weighted redundance)\n",
    "print(\"With Binary method, chi_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, CG_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, binary_cluster, redundant_cluster_check_with_child_cluster_mean_red_greater_than_parent_cluster_mean_redundance_randomly_taken_10_features, JMI with condition red_less_than_red_critical_val BC\")\n",
    "produce_result()\n",
    "############################## VEHECLE0 dataset in paper result ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula,\n",
    "# CG_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, binary_cluster,\n",
    "# redundant_cluster_check_with_child_cluster_mean_red_greater_than_parent_cluster_mean_redundance_randomly_taken_10_features,\n",
    "# JMI with condition jmi_greater_than_jmi_critical_val BC\n",
    "# (create_cluster_to_get_final_feature_subset_6 weighted redundance)\n",
    "produce_result_for_plos_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula,\n",
    "# CG_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, binary_cluster,\n",
    "# redundant_cluster_check_with_child_cluster_mean_red_greater_than_parent_cluster_mean_redundance_randomly_taken_10_features,\n",
    "# JMI with condition jmi_greater_than_jmi_critical_val BC\n",
    "# (create_cluster_to_get_final_feature_subset_6 weighted redundance)\n",
    "print(\"With Binary method, chi_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, CG_with_max_entropy_normalization_new_with_BC_from_wiki_normalization_formula, binary_cluster, redundant_cluster_check_with_child_cluster_mean_red_greater_than_parent_cluster_mean_redundance_randomly_taken_10_features, JMI with condition red_less_than_red_critical_val BC\")\n",
    "produce_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df = pd.DataFrame(data=csv_results, columns = labels )\n",
    "# result_df.to_csv ('result_with_FAST_JMI_Chi.csv', sep=\",\", index=None)\n",
    "result_df.to_csv (output_file_name+'.csv', sep=\",\", index=None)\n",
    "print(result_df.head(8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()\n",
    "irrelevant_feature_storing_file.close()\n",
    "per_fold_feature_storing_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_feature_list_with_frequency_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast \n",
    "def get_feature_list_with_frequency_count(dir, filename):\n",
    "  file1 = open(dir + filename + '_per_fold.txt', 'r')\n",
    "  Lines = file1.readlines()\n",
    "  file1.close()\n",
    "\n",
    "  all_fold_feature_list =[]\n",
    "#   count = 0\n",
    "  # Strips the newline character\n",
    "  \n",
    "  for line in Lines:\n",
    "#     count += 1\n",
    "#     print(count)\n",
    "#     print(line.strip())\n",
    "    s = line.strip()\n",
    "#     print(type(s))\n",
    "    res = ast.literal_eval(s)   \n",
    "#     print(res)\n",
    "#     print(type(res))\n",
    "#     print(res[0])\n",
    "    all_fold_feature_list.extend(res)\n",
    "#     print(len(res))\n",
    "\n",
    "#   print(len(all_fold_feature_list))\n",
    "#   print(all_fold_feature_list)\n",
    "\n",
    "  elements_count = {}\n",
    "  for element in all_fold_feature_list:\n",
    "   # checking whether it is in the dict or not\n",
    "    if element in elements_count:\n",
    "      # incerementing the count by 1\n",
    "      elements_count[element] += 1\n",
    "    else:\n",
    "      # setting the count to 1\n",
    "      elements_count[element] = 1\n",
    "  \n",
    "#   # printing the elements frequencies\n",
    "#   for key, value in elements_count.items():\n",
    "#      print(f\"{key}: {value}\")\n",
    "\n",
    "  sorted_elements_list = list (OrderedDict(sorted(elements_count.items(),reverse=True, key=itemgetter(1))) )\n",
    "\n",
    "  return sorted_elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir = \"FAST_v6_2_binary_method_base/\"\n",
    "# merged_GDS3341\n",
    "# merged_GDS3858\n",
    "# merged_GDS4167\n",
    "# merged_GDS4168\n",
    "# merged_GDS4824\n",
    "filename = 'merged_GDS4824'\n",
    "sorted_feature_list_with_frequency_count = get_feature_list_with_frequency_count(dir, filename)\n",
    "print(len(sorted_feature_list_with_frequency_count))\n",
    "print(sorted_feature_list_with_frequency_count)\n",
    "# print(sorted_feature_list_with_frequency_count[len(sorted_feature_list_with_frequency_count)-1])\n",
    "# print(sorted_feature_list_with_frequency_count[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(dir + filename + '_feature_list_sorted_with_frequency_count.txt', 'w+')\n",
    "for feature in sorted_feature_list_with_frequency_count:\n",
    "  file1.write(feature + '\\n')\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSCHBpCDwTRC"
   },
   "source": [
    "CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('test.pkl','wb')\n",
    "# obj_1 = ['test_1', {'ability', 'mobility'}]\n",
    "# obj_2 = ['test_2', {'ability', 'mobility'}]\n",
    "# obj_3 = ['test_3', {'ability', 'mobility'}]\n",
    "\n",
    "# pickle.dump(obj_1, file)\n",
    "# pickle.dump(obj_2, file)\n",
    "# pickle.dump(obj_3, file)\n",
    "\n",
    "# file.close()\n",
    "\n",
    "# file = open('test.pkl', 'rb')\n",
    "# # obj_1 = pickle.load(file)\n",
    "# obj_2 = pickle.load(file)\n",
    "# obj_3 = pickle.load(file)\n",
    "# print(obj_1)\n",
    "# print(obj_2)\n",
    "# print(obj_3)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoVlAynNkgZX"
   },
   "outputs": [],
   "source": [
    "# pip install wittgenstein\n",
    "# import wittgenstein as lw\n",
    "# ripper_clf = lw.RIPPER() # Or irep_clf = lw.IREP() to build a model using IREP\n",
    "# ripper_clf.fit(train, class_feat='Party') # Or call .fit with params train_X, train_y\n",
    "# ripper_clf\n",
    "# <RIPPER object with fit ruleset (k=2, prune_size=0.33, dl_allowance=64)> # Hyperparameter details available in the docstrings and TDS article below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# directory = \"../all dataset/csv dataset/GSE gene dataset\"\n",
    "# datasets = os.listdir(directory)\n",
    "# print(len(datasets))\n",
    "# for dataset in datasets[:]:\n",
    "#   file_name = \"../all dataset/csv dataset/GSE gene dataset/\"+dataset\n",
    "#   df = pd.read_csv (file_name)\n",
    "#   check_for_categorical_feature(dataset, df)\n",
    "#   print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GX8tT8AW-DxZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# directory = \"../all dataset/csv dataset/sadia apu paper dataset\"\n",
    "directory = \"../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format\"\n",
    "files = os.listdir(directory)\n",
    "print(len(files))\n",
    "for file in files[:]:\n",
    "  print(file)\n",
    "  file_name = '../all dataset/csv dataset/Microarray_data_tab_delimited_csv_format/'+file\n",
    "  a = pd.read_csv (file_name)\n",
    "  print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # new_df = df.loc[ df['class'] != 'WALKING_UPSTAIRS' ]\n",
    "# # directory = \"../all dataset/csv dataset/sadia apu paper dataset\"\n",
    "# directory = \"../all dataset/csv dataset/Five dataset\"\n",
    "# files = os.listdir(directory)\n",
    "# print(len(files))\n",
    "# for file in files[:]:\n",
    "  \n",
    "#   file_name = \"../all dataset/csv dataset/Five dataset/\"+file\n",
    "#   a = pd.read_csv (file_name)\n",
    "#   new_df = a.rename(columns={'LABEL': '0'})\n",
    "#   new_df.to_csv (\"../all dataset/csv dataset/\"+file, sep=\",\", index=None)\n",
    "#   print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-DfHpF44AM8_"
   ],
   "name": "FAST minimum spanning tree_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
